terpretable prediction results.
References
Afouras, T.; Chung, J. S.; Senior, A.; Vinyals, O.; and Zisserman,
A. 2018. Deep audio-visual speech recognition. IEEE TPAMI.
Baytas, I. M.; Xiao, C.; Zhang, X.; Wang, F.; Jain, A. K.; and Zhou,
J. 2017. Patient subtyping via time-aware lstm networks. In KDD,
65–74.
Breiman, L. 2001. Random forests. Machine learning 45(1):5–32.
Camburu, O.-M.; Rockt¨aschel, T.; Lukasiewicz, T.; and Blunsom,
P. 2018. e-snli: natural language inference with natural language
explanations. In NIPS, 9539–9549.
Che, C.; Xiao, C.; Liang, J.; Jin, B.; Zho, J.; and Wang, F. 2017. An
rnn architecture with dynamic temporal matching for personalized
predictions of parkinson’s disease. In SIAM on Data Mining, 198–
206.
Che, Z.; Purushotham, S.; Cho, K.; Sontag, D.; and Liu, Y. 2018.
Recurrent neural networks for multivariate time series with missing
values. Scientiﬁc reports 8(1):6085.
Choi, E.; Bahadori, M. T.; Sun, J.; Kulas, J.; Schuetz, A.; and Stew-
art, W. 2016. Retain: An interpretable predictive model for health-
care using reverse time attention mechanism. In NIPS, 3504–3512.
Choi, E.; Bahadori, M. T.; Song, L.; Stewart, W. F.; and Sun, J.
2017. Gram: graph-based attention model for healthcare represen-
tation learning. In KDD, 787–795.
Chung, J.; Gulcehre, C.; Cho, K.; and Bengio, Y. 2014. Empirical
evaluation of gated recurrent neural networks on sequence model-
ing. arXiv preprint arXiv:1412.3555.
Comon, P. 2014. Tensors: a brief introduction. IEEE Signal Pro-
cessing Magazine 31(3):44–53.
Fu, J.; Liu, J.; Tian, H.; Li, Y.; Bao, Y.; Fang, Z.; and Lu, H. 2019.
Dual attention network for scene segmentation. In CVPR, 3146–
3154.
Gao, L.; Li, X.; Song, J.; and Shen, H. T. 2019. Hierarchical lstms
with adaptive attention for visual captioning. IEEE TPAMI.
Heo, J.; Lee, H. B.; Kim, S.; Lee, J.; Kim, K. J.; Yang, E.; and
Hwang, S. J. 2018. Uncertainty-aware attention for reliable inter-
pretation and prediction. In NIPS, 909–918.
Hosmer Jr, D. W.; Lemeshow, S.; and Sturdivant, R. X. 2013. Ap-
plied logistic regression, volume 398. John Wiley & Sons.
Johnson, A. E.; Pollard, T. J.; Shen, L.; Li-wei, H. L.; Feng, M.;
Ghassemi, M.; Moody, B.; Szolovits, P.; Celi, L. A.; and Mark,
R. G. 2016. Mimic-iii, a freely accessible critical care database.
Scientiﬁc data 3:160035.
Kang, A.; Tan, Q.; Yuan, X.; Lei, X.; and Yuan, Y. 2017. Short-
term wind speed prediction using eemd-lssvm model. Advances in
Meteorology 2017:1–22.
Li, S.; Li, W.; Cook, C.; Zhu, C.; and Gao, Y. 2018. Independently
recurrent neural network (indrnn): Building a longer and deeper
rnn. In CVPR, 5457–5466.
Lipton, Z. C.; Kale, D.; and Wetzel, R. 2016. Directly model-
ing missing data in sequences with rnns: Improved classiﬁcation of
clinical time series. In Machine Learning for Healthcare Confer-
ence, 253–270.
Liu, B.; Li, Y.; Sun, Z.; Ghosh, S.; and Ng, K. 2018a. Early pre-
diction of diabetes complications from electronic health records: A
multi-task survival analysis approach. In AAAI.
Liu, L.; Shen, J.; Zhang, M.; Wang, Z.; and Tang, J. 2018b. Learn-
ing the joint representation of heterogeneous temporal events for
clinical endpoint prediction. In AAAI.
Ma, F.; Chitta, R.; Zhou, J.; You, Q.; Sun, T.; and Gao, J. 2017.
Dipole: Diagnosis prediction in healthcare via attention-based bidi-
rectional recurrent neural networks. In KDD, 1903–1911.
Ma, F.; You, Q.; Xiao, H.; Chitta, R.; Zhou, J.; and Gao, J. 2018.
Kame: Knowledge-based attention model for diagnosis prediction
in healthcare. In CIKM, 743–752.
Pang, B.; Zha, K.; Cao, H.; Shi, C.; and Lu, C. 2019. Deep rnn
framework for visual sequential applications. In CVPR, 423–432.
Pollard, T. J.; Johnson, A. E.; Raffa, J. D.; Celi, L. A.; Mark, R. G.;
and Badawi, O. 2018. The eicu collaborative research database,
a freely available multi-center database for critical care research.
Scientiﬁc data 5.
Shankar, S., and Sarawagi, S. 2019. Posterior attention models for
sequence to sequence learning. In ICLR.
Shickel, B.; Tighe, P. J.; Bihorac, A.; and Rashidi, P. 2017. Deep
ehr: a survey of recent advances in deep learning techniques for
electronic health record (ehr) analysis. IEEE JBHI 22(5):1589–
1604.
Shukla, S. N., and Marlin, B. M. 2019. Interpolation-prediction
networks for irregularly sampled time series. In ICLR.
Sin, D. D.; Man, S. P.; and Marrie, T. J. 2005. Arterial carbon
dioxide tension on admission as a marker of in-hospital mortal-
ity in community-acquired pneumonia. The American journal of
medicine 118(2):145–150.
Song, H.; Rajan, D.; Thiagarajan, J. J.; and Spanias, A.
2018.
Attend and diagnose: Clinical time series analysis using attention
models. In AAAI.
Suo, Q.; Ma, F.; Canino, G.; Gao, J.; Zhang, A.; Veltri, P.; and
Agostino, G. 2017. A multi-task framework for monitoring health
conditions via attention-based recurrent neural networks. In AMIA,
1665–1674.
Tan, Q.; Ma, A. J.; Deng, H.; Wong, V. W.-S.; Tse, Y.-K.; Yip, T.
C.-F.; Wong, G. L.-H.; Ching, J. Y.-L.; Chan, F. K.-L.; and Yuen, P.-
C. 2018. A hybrid residual network and long short-term memory
method for peptic ulcer bleeding mortality prediction. In AMIA,
998–1007.
Tan, Q.; Ma, A. J.; Ye, M.; Yang, B.; Deng, H.; Wong, V. W.-S.;
Tse, Y.-K.; Yip, T. C.-F.; Wong, G. L.-H.; Ching, J. Y.-L.; et al.
2019. Ua-crnn: Uncertainty-aware convolutional recurrent neural
network for mortality risk prediction. In CIKM, 109–118.
Xu, Y.; Biswal, S.; Deshpande, S. R.; Maher, K. O.; and Sun, J.
2018. Raim: Recurrent attentive and intensive model of multimodal
patient monitoring data. In KDD, 2565–2573.
Ye, M.; Lan, X.; Wang, Z.; and Yuen, P. C.
2019a.
Bi-
directional center-constrained top-ranking for visible thermal per-
son re-identiﬁcation. IEEE TIFS.
Ye, M.; Li, J.; Ma, A. J.; Zheng, L.; and Yuen, P. C. 2019b. Dy-
namic graph co-matching for unsupervised video-based person re-
identiﬁcation. IEEE TIP 28(6):2976–2990.
Ye, M.; Zhang, X.; Yuen, P. C.; and Chang, S.-F. 2019c. Unsu-
pervised embedding learning via invariant and spreading instance
feature. In CVPR, 6210–6219.
Yuan, X.; Chen, C.; Yuan, Y.; Huang, Y.; and Tan, Q. 2015. Short-
term wind power prediction based on lssvm–gsa model. Energy
Conversion and Management 101:393–401.
Yuan, X.; Tan, Q.; Lei, X.; Yuan, Y.; and Wu, X. 2017. Wind power
prediction using hybrid autoregressive fractionally integrated mov-
ing average and least square support vector machine.
Energy
129:122–137.
937
