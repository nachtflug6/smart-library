YOON et al.: ESTIMATING MISSING DATA IN TEMPORAL DATA STREAMS USING MULTI-DIRECTIONAL RECURRENT NEURAL NETWORKS
1487
TABLE VI
CONGENIALITY OF IMPUTATION MODELS
Fig. 6 shows that M-RNN outperforms the best benchmarks
for every sub-sample and the improvement in performance
is greater for the sub-samples for which more data is miss-
ing. The improvement in performance is statistically signiﬁcant
(p-value < 0.05) when an additional 30% or more of the mea-
surements - i.e., a total of 82.5% of the measurements - (or
of the most important features for Setting B) - are missing. In
particular, the prediction performance of M-RNN is much less
sensitive to the amount of data that is missing and to which data
is missing.
G. Congeniality of the Model
As [26] has emphasized, an extremely desirable aspect of any
imputation method is that it produce imputed values in a man-
ner that is consistent and preserves the original relationships
between features and labels; [26] refers to this as congeniality.
Congeniality of an imputation model can be evaluated with re-
spect to a particular model of the feature-label relationships by
computing the model parameters for the true complete data and
the imputed data and measuring the difference between parame-
ters according to some speciﬁed metric. Of course no imputation
method can be expected to be perfectly congenial, but we argue
that our method is more congenial – i.e., better preserves the
relationships between features and labels – than benchmarks.
To see this, we exploit the Biobank dataset; this is a complete
dataset, so that it is possible to compare the relationship between
the actual (original) data and labels and the relationship between
the the imputed data and labels.
In our particular experiment, we delete 20% of the data and
impute the missing data using our M-RNN and the 4 best bench-
marks (the method of [24], Cubic Interpolation, MissForest and
Matrix Completion). As a model of the feature-label relation-
ship, we use a logistic regression. As a metric of the difference
between the logistic regression parameters w for the actual
data and ˆw for the imputed data (which can be interpreted as
a measure of the uncongeniality of the imputation) we report
both the mean bias ∥w −ˆw∥1 and the root mean squared error
∥w −ˆw∥2.
As can be seen in Table VI, in comparison with the 4 best
benchmarks, M-RNN achieves both smaller mean bias and small
root mean squared error between the original and imputed rep-
resentations of feature-label relationship. (With the exception
of MissForest, all the performance improvements of M-RNN
are statistically signiﬁcant at the 95% level.) Thus our method
TABLE VII
PERFORMANCE COMPARISON FOR MISSING DATA ESTIMATION FOR MCAR
AND MAR SETTINGS ON THE BIOBANK DATASET
is more congenial (to the logistic regression model) than the
benchmarks.
H. M-RNN When Data is Missing at Random
The experiments above are designed to demonstrate the su-
periority of the M-RNN framework in comparison to the bench-
marks in settings where data is Missing Completely at Random
(MCAR) [3] but it is important to understand the comparison in
the settings where data is Missing at Random (MAR) - but not
Missing Completely at Random. In this subsection, we show that
M-RNN also outperforms the benchmarks when data is Miss-
ing at Random (MAR). (The assumption that data is Missing at
Random is standard in the medical setting.)
To accomplish this, we again begin with the complete
Biobank dataset and remove 20% of the data. However in this
case we do not remove data completely at random; rather, we
use the following procedure.1 Using induction, we deﬁne the
probability that the component i of sample n at time t is ob-
served, conditional on the missingness and values (if observed)
of the previous i −1 components at time t [3] to be
P t
i (n) = pm · N · e−
j < i w j m t
j (n)xt
j (n)+bj (1−m t
j (n))
N
l=1 e−
j < i w j m t
j (l)xt
j (l)+bj (1−m t
j (l))
where pm corresponds to the average missing rate (in our ex-
periment, pm = 0.2), and wj, bj are sampled from U(0, 1) (but
are only sampled once for the entire dataset). We sequentially
sample mt
1, ..., mt
D for each feature vector.
We compare the RMSE of M-RNN architecture against four
competitive benchmarks: [24], Cubic Interpolation, MissForest,
and Matrix Completion in both MCAR and MAR settings. As
can be seen in Table VII, M-RNN outperforms other state-of-
the-art imputation methods in both MCAR and MAR settings.
Additional experimental results and the details of the
experiments, including standard deviations of the reported
results, can be found in the Supplementary Materials:
http://medianetlab.ee.ucla.edu/papers/TBME_MRNN_SM.pdf
VII. CONCLUSION
The problem of reconstructing/estimating missing data is
ubiquitous in many settings – especially in longitudinal medical
1Other procedures are certainly possible.
Authorized licensed use limited to: Chalmers University of Technology Sweden. Downloaded on October 28,2024 at 18:11:05 UTC from IEEE Xplore.  Restrictions apply. 
