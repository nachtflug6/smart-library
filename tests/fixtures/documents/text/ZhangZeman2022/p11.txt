Published as a conference paper at ICLR 2022
REFERENCES
Denis Agniel, Isaac S Kohane, and Grifﬁn M Weber. Biases in electronic health record data due to
processes within the healthcare system: retrospective observational study. British Medical Journal,
361, 2018.
Zhengping Che, Sanjay Purushotham, Kyunghyun Cho, David Sontag, and Yan Liu. Recurrent neural
networks for multivariate time series with missing values. Scientiﬁc Reports, 8(1):1–12, 2018.
Tian Qi Chen, Yulia Rubanova, Jesse Bettencourt, and David K Duvenaud. Neural ordinary differen-
tial equations. In NeurIPS, 2018.
Zekai Chen, E Jiaze, Xiao Zhang, Hao Sheng, and Xiuzheng Cheng. Multi-task time series forecasting
with shared attention. In ICDM Workshop, pp. 917–925, 2020.
Kyunghyun Cho, Bart Van Merriënboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger
Schwenk, and Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for
statistical machine translation. 2014.
Edward Choi, Zhen Xu, Yujia Li, Michael Dusenberry, Gerardo Flores, Emily Xue, and Andrew Dai.
Learning the graphical structure of electronic health records with graph convolutional transformer.
In AAAI, volume 34, pp. 606–613, 2020.
Federico Errica, Davide Bacciu, and Alessio Micheli. Graph mixture density networks. In ICML, pp.
3025–3035, 2021.
Chenguang Fang and Chen Wang. Time series data imputation: A survey on deep learning approaches.
arXiv:2011.11347, 2020.
Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber, Lhassane Idoumghar, and Pierre-Alain
Muller. Deep learning for time series classiﬁcation: a review. Data Mining and Knowledge
Discovery, 33(4):917–963, 2019.
Matthias Fey, Jan-Gin Yuen, and Frank Weichert. Hierarchical inter-message passing for learning on
molecular graphs. arXiv:2006.12179, 2020.
Mikhail Galkin, Priyansh Trivedi, Gaurav Maheshwari, Ricardo Usbeck, and Jens Lehmann. Message
passing for hyper-relational knowledge graphs. arXiv:2009.10847, 2020.
Prakhar Ganesh, Yao Chen, Xin Lou, Mohammad Ali Khan, Yin Yang, Hassan Sajjad, Preslav Nakov,
Deming Chen, and Marianne Winslett. Compressing large-scale transformer-based models: A case
study on bert. Transactions of the Association for Computational Linguistics, 9:1061–1080, 2021.
Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. Neural
message passing for quantum chemistry. In ICML, pp. 1263–1272. PMLR, 2017.
Ary L. Goldberger, Luis A. Nunes Amaral, L Glass, Jeffrey M. Hausdorff, Plamen Ch. Ivanov,
Roger G. Mark, Joseph E. Mietus, George B. Moody, Chung-Kang Peng, and Harry Eugene
Stanley. PhysioBank, PhysioToolkit, and PhysioNet: components of a new research resource for
complex physiologic signals. Circulation, 101 23:E215–20, 2000.
Max Horn, Michael Moor, Christian Bock, Bastian Rieck, and Karsten Borgwardt. Set functions for
time series. pp. 4303–4313, 2020.
Jie Hu, Li Shen, and Gang Sun. Squeeze-and-excitation networks. In CVPR, pp. 7132–7141, 2018.
Wenjie Hu, Yang Yang, Ziqiang Cheng, Carl Yang, and Xiang Ren. Time-series event prediction
with evolutionary state graph. In WSDM, pp. 580–588, 2021.
Ziniu Hu, Yuxiao Dong, Kuansan Wang, and Yizhou Sun. Heterogeneous graph transformer. In The
Web Conference, pp. 2704–2710, 2020.
Ekaterina Kalinicheva, Dino Ienco, Jérémie Sublime, and Maria Trocan. Unsupervised change
detection analysis in satellite image time series using deep learning combined with graph-based
approaches. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,
13:1450–1466, 2020.
11
