layer of a model. Although the ”N BDLSTM + LSTM” has more parameters than the ”N LSTM + BDLSTM”, when these models has
same amount of layers, the ”N LSTM + BDLSTM” acheives better prediction perfromance.
The differences between the experimental results on two datasets are also obvious. The BDLSTM and the ”N LSTM + BDLSTM”
can achieve much better perforamnce than other types of models on the PEMS-BAY dataset. However, the superiority of BDLSTM-
based models tested on the LOOP-SEA dataset is not as evident as that on the PEMS-BAY dataset. This phenomemon may be lead by
that the traffic state sequences in the LOOP-SEA dataset contain more Irregular variations.
4.4. Training time
Fig. 4a shows the training time per epoch of the compared models tested on the LOOP-SEA dataset. Considering the length of the
input time series is fixed, the training time of a model is mostly related to the amount of parameters. Since the BDLSTM contains two
LSTMs, the training time of BDLSTM is nearly double of that of LSTM. The training times of those multi-layer models are nearly
linearly related to the number of layers. Since the ”N BDLSTM + LSTM” and the ”N LSTM + BDLSTM” are the combinations of the
BDLSTM and the LSTM, their training times are between those of multi-layer BDLSTMs and LSTMs.
Table 1
Performance of RNN-Based models for network-wide traffic speed prediction on LOOP-SEA dataset.
Models
Performance of Models on LOOP-SEA Dataset
N = 0
N = 1
N = 2
N = 3
MAE
MAPE
RMSE
MAE
MAPE
RMSE
MAE
MAPE
RMSE
MAE
MAPE
RMSE
N + 1 LSTM
3.769
11.021
6.106
2.389
5.681
3.562
2.417
5.800
3.634
2.643
6.606
4.052
N + 1 BDLSTM
3.027
6.815
5.265
2.336
5.475
3.507
2.405
3.631
5.723
2.472
5.947
3.750
N BDLSTM + LSTM
–
–
–
2.523
6.153
3.809
2.464
5.954
3.707
2.579
6.344
3.911
N LSTM + BDLSTM
–
–
–
2.362
5.552
3.542
2.448
5.875
3.707
2.580
6.317
3.941
Table 2
Performance of RNN-Based models for network-wide traffic speed prediction on PEMS-BAY dataset.
Models
Performance of Models on PEMS-BAY Dataset
N = 0
N = 1
N = 2
N = 3
MAE
MAPE
RMSE
MAE
MAPE
RMSE
MAE
MAPE
RMSE
MAE
MAPE
RMSE
N + 1 LSTM
3.286
6.530
4.914
2.315
3.989
3.085
2.363
4.131
3.198
5.444
13.656
9.185
N + 1 BDLSTM
1.659
3.003
4.295
1.186
2.251
1.927
1.337
2.583
2.252
1.569
3.142
2.822
N BDLSTM + LSTM
–
–
–
2.509
4.520
3.476
2.398
4.223
3.252
5.618
13.831
9.192
N LSTM + BDLSTM
–
–
–
1.333
2.545
2.161
1.526
3.023
2.671
2.532
4.732
6.223
Fig. 4. (a) Training time per epoch of the compared models tested on the LOOP-SEA dataset. (b) Boxplot of MAE versus number of time lags. The
MAEs are generated by the BDLSTM + LSTM model tested on the LOOP-SEA dataset. The unit of one time lag (time step) is 5 min.
Z. Cui, et al.
Transportation Research Part C 118 (2020) 102674
9
