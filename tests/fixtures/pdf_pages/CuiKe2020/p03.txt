the deep learning model design for traffic prediction problems. Experiments based on two real-world datasets with different missing
value patterns indicate that the proposed architecture can achieve outstanding prediction results. In summary, our contributions can
be summarized as follows:
1. We propose an LSTM structure with an imputation unit, i.e. LSTM-I, to infer and fill the missing values in the spatial–temporal
input data and in return to help improve prediction accuracy.
2. We propose a stacked bidirectional and unidirectional LSTM architecture. i.e. SBU-LSTM, for network-wide traffic forecasting.
This stacked architecture with multiple layersis flexible. The evaluation of the prediction capability of stacked LSTM- or BDLSTM-
based models has great potential to facilitate the design of neural network models for traffic prediction.
3. The trade-off between model capacity and complexity is evaluated and discussed.
4. Two real-world traffic state data is tested in this study and the LOOP-SEA dataset is published via Github Cui et al. (2016) and
Zenodo Wang et al. (2019).
2. Literature review
2.1. Deep learning based traffic prediction
Deep learning-based models generated the state-of-the-art performance for traffic forecasting. Ever since the precursory study of
utilizing NN into the traffic prediction problem was proposed Hua and Faghri (1994), many NN-based methods, like feed-forward NN
Gers et al. (1999), fuzzy NN Yin et al. (2002), and recurrent NN (RNN) Van Lint et al. (2002) are adopted for traffic forecasting
problems more than ten years ago. Ma et al. Ma et al. (2015) firstly adopt the LSTM to forecast traffic speed. Several other studies
utilize the LSTM to forecast travel time Duan et al. (2016), congestion Chen et al. (2016), and traffic flow Zhao et al. (2017). Song
et al. Song et al. (2016) utilized shared hidden LSTM layers to help predict human mobility and transportation mode. Cui et al. Cui
et al. (2018) adopted bidirectional LSTM in the traffic prediction problem. Yu et al. Yu et al. (2017a) combine the convolutional
neural network with RNN to predict transportation states. There are many studies forecasting traffic from other perspectives, like
learning traffic as images Ma et al. (2017) or graphs Cui et al. (2019) by combining convolutional based neural networks.
2.2. Combining imputation and prediction
One option to deal with missing values is the skipping mechanism, which is usually used in the dropout process of RNNs Gal and
Ghahramani (2016). The other one is data imputation. Interpolation Kreindler and Lumsden (2012), and spline De Boor et al. (1978)
methods are simple and efficient for data imputation, but they cannot capture variable correlations and complex patterns to perform
imputation. Various data imputation methods for time series, including regression Chen et al. (2003), spectral analysis Mondal and
Percival (2010), EM algorithm García-Laencina et al. (2010), and matrix factorization Koren et al. (2009) Chen et al. (2019b) have
been developed and applied to estimate missing data. Among these non-deep learning-based models, matrix factorization methods
normally can achieve state-of-the-art prediction accuracy. A new Bayesian temporal matrix factorization method SSun and Chenun
and Chen (2019) is proposed to solve spatiotemporal data prediction problems when there is missing values in the input data. This
method can deal with missing values and achieve good prediction accuracy. However, the mechanisms of these methods and the sizes
of the dataset used to train models are greatly different from those of deep learning-based models. Besides, combining these data
imputation models with traffic prediction models often leads to a two-step process. To overcome this weakness, Che et al. Che et al.
(2018) firstly exploit to use a GRU-based model, GRU-D, to combine imputation and prediction models by designing a decay me-
chanism for data imputation.
3. Methodology
3.1. Notations
A time series of network-wide traffic states with D sensor stations can be denoted as
=
…
×
X
x
x
x T
{ _1,
_2,
, _ }T
T
D with T time
steps. Each vector x t
_
D denotes the D sensors’ traffic states at time t, whose elements x t
_ d represents the traffic state of d-th
sensor station. It should be noted that the traffic state can refer to traffic speed, travel time, traffic volume, etc. In this paper,the traffic
state specifically refers to traffic speed, which is consistent with the tested datasets in the experiment section.
In reality, traffic sensors, like inductive loop detectors, may fail due to the breakdown of wire insulation or damage caused by
construction activities or electronics unit failure. The sensor failure further will lead to missing values in the collected data. To deal
with missing values, a masking vector m t
_
{0, 1}D is adopted to denote whether traffic states are missing at time step t. The masking
vector for x t
_ is defined as
=
m t
x t
is observed
_
1, if
_
0, otherwise
d
d
(1)
Accordingly, for a traffic state data sample
×
X
T
D, we can get a masking data sample,
=
…
×
M
m
m
m T
{
_1,
_2,
,
_ }T
T
D.
In this study, the traffic state prediction problem aims to learn a function F (·) to map T steps of historical traffic state data to the
Z. Cui, et al.
Transportation Research Part C 118 (2020) 102674
3
