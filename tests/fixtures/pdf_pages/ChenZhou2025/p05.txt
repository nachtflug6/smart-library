at any time is inﬂuenced by the current input value as well
as proceeding hidden states, and the use of ODE ensures
continuous-time transitions of hidden states across irregular
time intervals, thus effectively retaining the dynamic char-
acteristics within the sequence. 3) Finally, the mapping be-
tween the predicted value y and the hidden state from the
previous time step is established, given as:
y(h) = Wyhh + b,
(7)
where the output weights Wyh and the bias b can be directly
determined by extending the ridge regression solution:
˜
W = ( ˜HT ˜H + λI)−1 ˜HT X,
(8)
where ˜
W is the concat of the output weights Wyh and the
bias b, ˜H is the augmented matrix of hidden states with
additional all-ones columns. X represents the target values,
which are the data points at the next time step corresponding
to each hidden state. λ is the regularization parameter, and I
is the identity matrix.
The output weights and bias can be then extracted from
˜
W, obtaining the Ct-Echo readout model as Formula (7).
This transformation allows for a concise representation of
each sequence with the readout model.
Distance Metric between Ct-Echo Models
Representing each sequence with a ﬁtted model, the distance
between the Ct-Echo readout models should be deﬁned to
support further classiﬁcation of models (Chen et al. 2013).
Suppose two distinct Ct-Echo readout models, y1 and y2
mapping from RN (hidden layer dimension) to RM (output
layer dimension), are formulated as:
y1(h) = Wyh
1 h + b1,
y2(h) = Wyh
2 h + b2.
(9)
The deﬁnition of the 2-norm distance (Chen et al. 2013)
between y1(h) and y2(h) is given as:
L2(y1, y2) =
Z
C
||y1(h) −y2(h)||2dh
1/2
,
(10)
where C = [−1, 1]N is the domain of integration6.
By integrating Formula (9) into (10), the distance between
two Ct-Echo readout models could be estimated by:
Dis(y1, y2) = 1
3
N
X
j=1
M
X
i=1
ω2
i,j + ||b′||2,
(11)
where ωi,j is the (i, j) element of W′ = Wyh
1
−Wyh
2
and
b′ = b1 −b2. Utilizing Formula (11), the distance between
any two Ct-Echo readout models could be effectively mea-
sured, thus distance-based learning algorithms could be ap-
plied in the model space for further analysis.
6According to the iterative formula (1) and (5), hidden states h
are assumed to lie within the hypercube [−1, 1]N.
Anomaly Detection in the Ct-Echo Model Space
Anomaly detection involves classifying unknown irregular
sequences as either normal or speciﬁc types of anomalies.
Our approach consists of two phases: training and detection.
Training phase
Each labeled irregular sequence is ﬁrst
ﬁtted through Ct-Echo separately to obtain a correspond-
ing readout model. The ﬁtted model represents the original
data, mapping the corresponding sequence into the Ct-Echo
model space supported by the distance metric given in the
above subsection. A classiﬁer, such as Support Vector Ma-
chine (SVM) (Cortes and Vapnik 1995) or K-Nearest Neigh-
bors (KNN) (Altman 1992), is then trained on these models.
Detection phase
A newly collected irregular sequence is
ﬁrst ﬁtted with Ct-Echo, obtaining the readout model. This
model is then evaluated using the previously trained classi-
ﬁer to determine whether it is normal or belongs to a speciﬁc
type of anomaly, which directly corresponds to the category
of the original sequence.
Experimental Study
This section details experiments tested on several datasets,
followed by analysis of comparative experimental results
and the presentation of additional analytical experiments.
Introduction of the Utilized Datasets
Three datasets, CWRU, SU, and WHU are utilized, intro-
duced as follows7. For the default setting: 1) Assume se-
quences with irregular sampling, we randomly delete 50%
data points from each sequence (i.e., with the missing rate
of 50%)8; 2) Supposing labeled-data-limited scenarios,
for training, we use only 200 sequences per sub-dataset for
CWRU and SU, and 90 for WHU; for testing, we use 1800
sequences per sub-dataset for CWRU, 4800 per sub-dataset
for SU, and 90 for WHU.
• CWRU
Dataset
(Loparo
2012):
Comprises
2-
dimensional vibration signals from bearings under
four load conditions (sub-datasets A, B, C, D), each with
200 instances per category. A mixed dataset is denoted
as E. The dataset, with 2048 time steps per instance,
supports a 10-category classiﬁcation task (one normal
category and nine distinct anomaly categories).
• SU Dataset (Shao et al. 2019): Contains 8-dimensional
data for gearbox and bearing under two working condi-
tions, denoted as sub-datasets G20, G30 for gearboxes,
and B20, B30 for bearings, each with 1000 instances per
category. The dataset includes four faults and one normal
category, and each sample consists of 1024 time steps.
• WHU Dataset (Liu et al. 2019): Includes 1-dimensional
vibration data from a rotor system, collected at 1200 rev-
olutions per minute and a sampling frequency of 2048
7The experiments are conducted on a PC with CPU: Intel(R)
Core(TM) i9-13900k, and GPU: NVIDIA GeForce RTX 3080.
8Experiments and discussions under different missing rates are
subsequently presented, where the missing rate refers to the pro-
portion of data points removed from each sequence.
15735
