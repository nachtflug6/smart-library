Published as a conference paper at ICLR 2022
Patrick Kidger, James Morrill, James Foster, and Terry Lyons. Neural controlled differential equations
for irregular time series. arXiv:2005.08926, 2020.
Byung-Hoon Kim, Jong Chul Ye, and Jae-Jin Kim. Learning dynamic graph representation of brain
connectome with spatio-temporal attention. arXiv:2105.13495, 2021.
Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv:1412.6980,
2014.
Liying Li, Yang Liu, Tongquan Wei, and Xin Li. Exploring inter-sensor correlation for missing data
estimation. In IECON, pp. 2108–2114. IEEE, 2020a.
Michelle M Li, Kexin Huang, and Marinka Zitnik. Representation learning for networks in biology
and medicine: Advancements, challenges, and opportunities. arXiv:2104.04883, 2021.
S. C.-X. Li and B. M. Marlin. A scalable end-to-end gaussian process adapter for irregularly sampled
time series classiﬁcation. In NIPS, pp. 1804–1812, 2016.
Steven Cheng-Xian Li and Benjamin Marlin. Learning from irregularly-sampled time series: A
missing data perspective. In ICML, pp. 5937–5946. PMLR, 2020.
Xiaoxue Li, Yanmin Shang, Yanan Cao, Yangxi Li, Jianlong Tan, and Yanbing Liu. Type-aware
anchor link prediction across heterogeneous networks based on graph attention network. In AAAI,
volume 34, pp. 147–155, 2020b.
Wu Lin, Nicolas Hubacher, and Mohammad Emtiyaz Khan. Variational message passing with
structured inference networks. ICLR, 2018.
R. J. Little and D. B. Rubin. Statistical Analysis with Missing Data. John Wiley & Sons, 3 edition,
2014.
Qianli Ma, Sen Li, and Garrison Cottrell. Adversarial joint-learning recurrent neural network for
incomplete time series classiﬁcation. TPAMI, 2020.
Karl Øyvind Mikalsen, Cristina Soguero-Ruiz, Filippo Maria Bianchi, Arthur Revhaug, and Robert
Jenssen. Time series cluster kernels to exploit informative missingness and incomplete label
information. Pattern Recognition, 115:107896, 2021.
Daniel Neil, Michael Pfeiffer, and Shih-Chii Liu. Phased lstm: accelerating recurrent network training
for long or event-based sequences. In NIPS, pp. 3889–3897, 2016.
Giannis Nikolentzos, Antoine Tixier, and Michalis Vazirgiannis. Message passing attention networks
for document understanding. In AAAI, volume 34, pp. 8544–8551, 2020.
S Ravuri, K Lenc, M Willson, D Kangin, R Lam, P Mirowski, M Athanassiadou, S Kashem, S Madge,
R Prudden, et al. Skillful precipitation nowcasting using deep generative models of radar, arxiv.
Nature, 597:672–677, 2021.
Attila Reiss and Didier Stricker. Introducing a new benchmarked dataset for activity monitoring. In
ISWC, pp. 108–109, 2012.
Matthew A Reyna, Christopher S Josef, Russell Jeter, Supreeth P Shashikumar, M Brandon Westover,
Shamim Nemati, Gari D Clifford, and Ashish Sharma. Early prediction of sepsis from clinical data:
The physionet/computing in cardiology challenge 2019. Critical Care Medicine, 48(2):210–217,
2020.
Pau Riba, Andreas Fischer, Josep Lladós, and Alicia Fornés. Learning graph distances with message
passing neural networks. In ICPR, pp. 2239–2244. IEEE, 2018.
J. L. Schafer and J. W. Graham. Missing data: Our view of the state of the art. Psychological
Methods, 7(2), 2002.
Omer Berat Sezer, Mehmet Ugur Gudelek, and Ahmet Murat Ozbayoglu. Financial time series fore-
casting with deep learning: A systematic literature review: 2005–2019. Applied Soft Computing,
90:106181, 2020.
12
