{"document_id": "LuoCai2018", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2018, "arxiv_id": null, "title": "Multivariate Time Series Imputation with Generative Adversarial Networks", "abstract": "Multivariate time series usually contain a large number of missing values, which hinders the application of advanced analysis methods on multivariate time series data. Conventional approaches to addressing the challenge of missing values, including mean/zero imputation, case deletion, and matrix factorization-based imputation, are all incapable of modeling the temporal dependencies and the nature of complex distribution in multivariate time series. In this paper, we treat the problem of missing value imputation as data generation. Inspired by the success of Generative Adversarial Networks (GAN) in image generation, we propose to learn the overall distribution of a multivariate time series dataset with GAN, which is further used to generate the missing values for each sample. Different from the image data, the time series data are usually incomplete due to the nature of data recording process. A modiﬁed Gate Recurrent Unit is employed in GAN to model the temporal irregularity of the incomplete time series. Experiments on two multivariate time series datasets show that the proposed model outperformed the baselines in terms of accuracy of imputation. Experimental results also showed that a simple model on the imputed data can achieve state-of-the-art results on the prediction tasks, demonstrating the beneﬁts of our model in downstream applications.", "keywords": null, "venue": "32nd Conference on Neural Information Processing Systems (NeurIPS 2018)", "authors": ["Luo, Yonghong", "Cai, Xiangrui", "Zhang, Ying", "Xu, Jun", "Yuan, Xiaojie"], "url": null, "doi": null}}
{"document_id": "LiuYu2019", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2019, "arxiv_id": null, "title": "NAOMI: Non-Autoregressive Multiresolution Sequence Imputation", "abstract": "Missing value imputation is a fundamental problem in spatiotemporal modeling, from motion tracking to the dynamics of physical systems. Deep autoregressive models suffer from error propagation which becomes catastrophic for imputing long-range sequences. In this paper, we take a non-autoregressive approach and propose a novel deep generative model: Non-AutOregressive Multiresolution Imputation (NAOMI) to impute long-range sequences given arbitrary missing patterns. NAOMI exploits the multiresolution structure of spatiotemporal data and decodes recursively from coarse to fine-grained resolutions using a divide-and-conquer strategy. We further enhance our model with adversarial training. When evaluated extensively on benchmark datasets from systems of both deterministic and stochastic dynamics. In our experiments, NAOMI demonstrates significant improvement in imputation accuracy (reducing average error by 60% compared to autoregressive counterparts) and generalization for long-range sequences.", "keywords": null, "venue": "33rd Conference on Neural Information Processing Systems (NeurIPS 2019)", "authors": ["Liu, Yukai", "Yu, Rose", "Zheng, Stephan", "Zhan, Eric", "Yue, Yisong"], "url": null, "doi": null}}
{"document_id": "LuoZhang2019", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2019, "arxiv_id": null, "title": "E2GAN: End-to-End Generative Adversarial Network for Multivariate Time Series Imputation", "abstract": "The missing values, appear in most of multivariate time series, prevent advanced analysis of multivariate time series data. Existing imputation approaches try to deal with missing values by deletion, statistical imputation, machine learning based imputation and generative imputation. However, these methods are either incapable of dealing with temporal information or multi-stage. This paper proposes an end-to-end generative model E2GAN to impute missing values in multivariate time series. With the help of the discriminative loss and the squared error loss, E2GAN can impute the incomplete time series by the nearest generated complete time series at one stage. Experiments on multiple real-world datasets show that our model outperforms the baselines on the imputation accuracy and achieves state-of-the-art classification/regression results on the downstream applications. Additionally, our method also gains better time efficiency than multi-stage method on the training of neural networks.", "keywords": null, "venue": "Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence (IJCAI-19)", "authors": ["Luo, Yonghong", "Zhang, Ying", "Cai, Xiangrui", "Yuan, Xiaojie"], "url": null, "doi": null}}
{"document_id": "TangYao2020", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2020, "arxiv_id": null, "title": "Joint Modeling of Local and Global Temporal Dynamics for Multivariate Time Series Forecasting with Missing Values", "abstract": "Multivariate time series (MTS) forecasting is widely used in various domains, such as meteorology and traffic. Due to limitations on data collection, transmission, and storage, real-world MTS data usually contains missing values, making it infeasible to apply existing MTS forecasting models such as linear regression and recurrent neural networks. Though many efforts have been devoted to this problem, most of them solely rely on local dependencies for imputing missing values, which ignores global temporal dynamics. Local dependencies/patterns would become less useful when the missing ratio is high, or the data have consecutive missing values; while exploring global patterns can alleviate such problem. Thus, jointly modeling local and global temporal dynamics is very promising for MTS forecasting with missing values. However, work in this direction is rather limited. Therefore, we study a novel problem of MTS forecasting with missing values by jointly exploring local and global temporal dynamics. We propose a new framework LGnet, which leverages memory network to explore global patterns given estimations from local perspectives. We further introduce adversarial training to enhance the modeling of global temporal distribution. Experimental results on real-world datasets show the effectiveness of LGnet for MTS forecasting with missing values and its robustness under various missing ratios.", "keywords": null, "venue": "The Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI-20)", "authors": ["Tang, Xianfeng", "Yao, Huaxiu", "Sun, Yiwei", "Aggarwal, Charu", "Mitra, Prasenjit", "Wang, Suhang"], "url": null, "doi": null}}
{"document_id": "Li2020", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2020, "arxiv_id": null, "title": "Learning from Irregularly-Sampled Time Series: A Missing Data Perspective", "abstract": "Irregularly-sampled time series occur in many domains including healthcare. They can be challenging to model because they do not naturally yield a fixed-dimensional representation as required by many standard machine learning models. In this paper, we consider irregular sampling from the perspective of missing data. We model observed irregularly-sampled time series data as a sequence of index-value pairs sampled from a continuous but unobserved function. We introduce an encoder-decoder framework for learning from such generic indexed sequences. We propose learning methods for this framework based on variational autoencoders and generative adversarial networks. For continuous irregularly-sampled time series, we introduce continuous convolutional layers that can efficiently interface with existing neural network architectures. Experiments show that our models are able to achieve competitive or better classification results on irregularly-sampled multivariate time series compared to recent RNN models while offering significantly faster training times.", "keywords": null, "venue": "Proceedings of the 37th International Conference on Machine Learning (ICML), PMLR 119", "authors": ["Li, Steven Cheng-Xian", "Marlin, Benjamin M."], "url": null, "doi": null}}
{"document_id": "KidgerFoster2021", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2021, "arxiv_id": null, "title": "Neural SDEs as Infinite-Dimensional GANs", "abstract": "Stochastic differential equations (SDEs) are a staple of mathematical modelling of temporal dynamics. However, a fundamental limitation has been that such models have typically been relatively inflexible, which recent work introducing Neural SDEs has sought to solve. Here, we show that the current classical approach to fitting SDEs may be approached as a special case of (Wasserstein) GANs, and in doing so the neural and classical regimes may be brought together. The input noise is Brownian motion, the output samples are time-evolving paths produced by a numerical solver, and by parameterising a discriminator as a Neural Controlled Differential Equation (CDE), we obtain Neural SDEs as (in modern machine learning parlance) continuous-time generative time series models. Unlike previous work on this problem, this is a direct extension of the classical approach without reference to either prespecified statistics or density functions. Arbitrary drift and diffusions are admissible, so as the Wasserstein loss has a unique global minima, in the infinite data limit any SDE may be learnt. Example code has been made available as part of the torchsde repository.", "keywords": null, "venue": "Proceedings of the 38th International Conference on Machine Learning, PMLR 139", "authors": ["Kidger, Patrick", "Foster, James", "Li, Xuechen", "Oberhauser, Harald", "Lyons, Terry"], "url": null, "doi": null}}
{"document_id": "OhKim2021", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2021, "arxiv_id": null, "title": "STING: Self-attention based Time-series Imputation Networks using GAN", "abstract": "Time series data are ubiquitous in real-world applications. However, one of the most common problems is that the time series could have missing values by the inherent nature of the data collection process. So imputing missing values from multivariate (correlated) time series is imperative to improve a prediction performance while making an accurate data-driven decision. Conventional works for imputation simply delete missing values or fill them based on mean/zero. Although recent works based on deep neural networks have shown remarkable results, they still have a limitation to capture the complex generation process of multivariate time series. In this paper, we propose a novel imputation method for multivariate time series, called STING (Self-attention based Time-series Imputation Networks using GAN). We take advantage of generative adversarial networks and bidirectional recurrent neural networks to learn the latent representations of time series. In addition, we introduce a novel attention mechanism to capture the weighted correlations of a whole sequence and avoid the potential bias brought by unrelated ones. The experimental results on three real-world datasets demonstrate that STING outperforms the existing state-of-the-art methods in terms of imputation accuracy as well as downstream tasks with the imputed values therein.", "keywords": ["time-series imputation", "self-attention", "generative adversarial networks", "bidirectional rnn"], "venue": "IEEE International Conference on Data Mining (ICDM)", "authors": ["Oh, Eunkyu", "Kim, Taehun", "Ji, Yunhu", "Khyalia, Sushil"], "url": null, "doi": "10.1109/ICDM51629.2021.00155"}}
{"document_id": "MiaoWu2021", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2021, "arxiv_id": null, "title": "Generative Semi-supervised Learning for Multivariate Time Series Imputation", "abstract": "The missing values, widely existed in multivariate time series data, hinder the effective data analysis. Existing time series imputation methods do not make full use of the label information in real-life time series data. In this paper, we propose a novel semi-supervised generative adversarial network model, named SSGAN, for missing value imputation in multivariate time series data. It consists of three players, i.e., a generator, a discriminator, and a classifier. The classifier predicts labels of time series data, and thus it drives the generator to estimate the missing values (or components), conditioned on observed components and data labels at the same time. We introduce a temporal reminder matrix to help the discriminator better distinguish the observed components from the imputed ones. Moreover, we theoretically prove that, SSGAN using the temporal reminder matrix and the classifier does learn to estimate missing values converging to the true data distribution when the Nash equilibrium is achieved. Extensive experiments on three public real-world datasets demonstrate that, SSGAN yields a more than 15% gain in performance, compared with the state-of-the-art methods.", "keywords": null, "venue": "The Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI-21)", "authors": ["Miao, Xiaoye", "Wu, Yangyang", "Wang, Jun", "Gao, Yunjun", "Mao, Xudong", "Yin, Jianwei"], "url": null, "doi": null}}
{"document_id": "JeonKim2022", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2022, "arxiv_id": null, "title": "GT-GAN: General Purpose Time Series Synthesis with Generative Adversarial Networks", "abstract": "Time series synthesis is an important research topic in the ﬁeld of deep learning,\nwhich can be used for data augmentation. Time series data types can be broadly\nclassiﬁed into regular or irregular. However, there are no existing generative\nmodels that show good performance for both types without any model changes.\nTherefore, we present a general purpose model capable of synthesizing regular\nand irregular time series data. To our knowledge, we are the ﬁrst designing a\ngeneral purpose time series synthesis model, which is one of the most challenging\nsettings for time series synthesis. To this end, we design a generative adversarial\nnetwork-based method, where many related techniques are carefully integrated into\na single framework, ranging from neural ordinary/controlled differential equations\nto continuous time-ﬂow processes. Our method outperforms all existing methods.", "keywords": null, "venue": "36th Conference on Neural Information Processing Systems (NeurIPS 2022)", "authors": ["Jeon, Jinsung", "Kim, Jeonghak", "Song, Haryong", "Cho, Seunghyeon", "Park, Noseong"], "url": null, "doi": null}}
{"document_id": "MulyadiJun2022", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2021, "arxiv_id": null, "title": "Uncertainty-Aware Variational-Recurrent Imputation Network for Clinical Time Series", "abstract": "Electronic health records (EHR) consist of longitudinal clinical observations portrayed with sparsity, irregularity, and high dimensionality, which become major obstacles in drawing reliable downstream clinical outcomes. Although there exist great numbers of imputation methods to tackle these issues, most of them ignore correlated features, temporal dynamics, and entirely set aside the uncertainty. Since the missing value estimates involve the risk of being inaccurate, it is appropriate for the method to handle the less certain information differently than the reliable data. In that regard, we can use the uncertainties in estimating the missing values as the fidelity score to be further utilized to alleviate the risk of biased missing value estimates. In this work, we propose a novel variational-recurrent imputation network, which unifies an imputation and a prediction network by taking into account the correlated features, temporal dynamics, as well as uncertainty. Specifically, we leverage the deep generative model in the imputation, which is based on the distribution among variables, and a recurrent imputation network to exploit the temporal relations, in conjunction with utilization of the uncertainty. We validated the effectiveness of our proposed model on two publicly available real-world EHR datasets: 1) PhysioNet Challenge 2012 and 2) MIMIC-III, and compared the results with other competing state-of-the-art methods in the literature.", "keywords": ["bioinformatics", "deep generative model", "deep learning", "electronic health records", "in-hospital mortality prediction", "missing value imputation", "time-series modeling", "uncertainty"], "venue": "IEEE Transactions on Cybernetics", "authors": ["Mulyadi, Ahmad Wisnu", "Jun, Eunji", "Suk, Heung-Il"], "url": "https://doi.org/10.1109/TCYB.2021.3053599", "doi": "10.1109/TCYB.2021.3053599"}}
{"document_id": "JhinJo2023", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2023, "arxiv_id": null, "title": "Learnable Path in Neural Controlled Differential Equations", "abstract": "Neural controlled differential equations (NCDEs), which are continuous analogues to recurrent neural networks (RNNs), are a specialized model in (irregular) time-series processing. In comparison with similar models, e.g., neural ordinary differential equations (NODEs), the key distinctive characteristics of NCDEs are i) the adoption of the continuous path created by an interpolation algorithm from each raw discrete time-series sample and ii) the adoption of the Riemann–Stieltjes integral. It is the continuous path which makes NCDEs be analogues to continuous RNNs. However, NCDEs use existing interpolation algorithms to create the path, which is unclear whether they can create an optimal path. To this end, we present a method to generate another latent path (rather than relying on existing interpolation algorithms), which is identical to learning an appropriate interpolation method. We design an encoder-decoder module based on NCDEs and NODEs, and a special training method for it. Our method shows the best performance in both time-series classification and forecasting.", "keywords": null, "venue": "The Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI-23)", "authors": ["Jhin, Sheo Yon", "Jo, Minju", "Kook, Seungji", "Park, Noseong"], "url": null, "doi": null}}
{"document_id": "Bignoumba2024", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2024, "arxiv_id": null, "title": "A new efficient ALignment-driven Neural Network for Mortality Prediction from Irregular Multivariate Time Series data", "abstract": "The irregularity of the time interval between observations in and across the stream is a key factor that leads to a drop in performance when classical machine learning or deep learning models are used for a downstream task requiring multivariate time series. Indeed, irregular multivariate time series not only increase the rate of missing values but also lead to data sparsity, which consequently makes the data almost unleverageable and/or ineffective for models. To tackle this scorching challenge, most of the pioneering approaches apply imputation or interpolation in their core, which might lead to embedding data with noise. To especially address this irregular multivariate time series issue, we introduce, in this paper, a new deep neural network model called ALignment-driven Neural Network. The innovative idea of our model is to transform the irregular multivariate time series into pseudo-aligned (or pseudo-regular) latent values. The latter are shown as a matrix, where the coefficients are the latent values of each feature at user-defined reference time points that are evenly spaced. They are obtained through a duplication process driven by an exponential decay mechanism. The obtained output is then passed to a Recurrent Neural Network model, which is undoubtedly the must-use model for regular time series data. To show that our model added value, we looked at the Intensive Care Unit mortality prediction task. In this unit, the physiological measurements used to make decisions have a problem with time irregularity. Leveraging the publicly available MIMIC-III, we compare the performance of our model to that of flagship models. In addition, we also performed extensive ablation studies to highlight the importance of specific components in our model. Interestingly enough, whenever data is collected 24 and 48 h after a patient’s admission, we outperform our pioneering competitors, i.e., +1.1% and +1.5% for the AUC score, +2.3% and +2.4% for the AUPRC score and +0.6% and +1.7% for the F1-score.", "keywords": ["aligned data", "deep learning", "electronic health records", "irregular multivariate time series"], "venue": "Expert Systems With Applications", "authors": ["Bignoumba, Nzamba", "Mellouli, Nedra", "Ben Yahia, Sadok"], "url": "https://doi.org/10.1016/j.eswa.2023.122148", "doi": "10.1016/j.eswa.2023.122148"}}
{"document_id": "FutomaHariharan2017", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2017, "arxiv_id": null, "title": "Learning to Detect Sepsis with a Multitask Gaussian Process RNN Classifier", "abstract": "We present a scalable end-to-end classifier that uses streaming physiological and medication data to accurately predict the onset of sepsis, a life-threatening complication from infections that has high mortality and morbidity. Our proposed framework models the multivariate trajectories of continuous-valued physiological time series using multitask Gaussian processes, seamlessly accounting for the high uncertainty, frequent missingness, and irregular sampling rates typically associated with real clinical data. The Gaussian process is directly connected to a black-box classifier that predicts whether a patient will become septic, chosen in our case to be a recurrent neural network to account for the extreme variability in the length of patient encounters. We show how to scale the computations associated with the Gaussian process in a manner so that the entire system can be discriminatively trained end-to-end using backpropagation. In a large cohort of heterogeneous inpatient encounters at our university health system we find that it outperforms several baselines at predicting sepsis, and yields 19.4% and 55.5% improved areas under the Receiver Operating Characteristic and Precision Recall curves as compared to the NEWS score currently used by our hospital.", "keywords": null, "venue": "Proceedings of the 34th International Conference on Machine Learning", "authors": ["Futoma, Joseph", "Hariharan, Sanjay", "Heller, Katherine"], "url": null, "doi": null}}
{"document_id": "ShuklaMarlin2019", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2019, "arxiv_id": null, "title": "INTERPOLATION-PREDICTION NETWORKS FOR IRREGULARLY SAMPLED TIME SERIES", "abstract": "In this paper, we present a new deep learning architecture for addressing the problem of supervised learning with sparse and irregularly sampled multivariate time series. The architecture is based on the use of a semi-parametric interpolation network followed by the application of a prediction network. The interpolation network allows for information to be shared across multiple dimensions of a multivariate time series during the interpolation stage, while any standard deep learning model can be used for the prediction network. This work is motivated by the analysis of physiological time series data in electronic health records, which are sparse, irregularly sampled, and multivariate. We investigate the performance of this architecture on both classification and regression tasks, showing that our approach outperforms a range of baseline and recently proposed models.", "keywords": null, "venue": "ICLR", "authors": ["Shukla, Satya Narayan", "Marlin, Benjamin M."], "url": "https://github.com/mlds-lab/interp-net", "doi": null}}
{"document_id": "LeeJun2022", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2022, "arxiv_id": null, "title": "Multi-View Integrative Attention-Based Deep Representation Learning for Irregular Clinical Time-Series Data", "abstract": "Electronic health record (EHR) data are sparse and irregular as they are recorded at irregular time intervals, and different clinical variables are measured at each observation point. In this work, to handle irregular multivariate time-series data, we consider the human knowledge of the aspects to be measured and time to measure them in different situations, known as multi-view features, which are indirectly represented in the data. We propose a scheme to realize multi-view features integration learning via a self-attention mechanism. Specifically, we devise a novel multi-integration attention module (MIAM) to extract complex information that is inherent in irregular time-series data. We explicitly learn the relationships among the observed values, missing indicators, and time interval between the consecutive observations in a simultaneous manner. In addition, we build an attention-based decoder as a missing value imputer that helps empower the representation learning of the interrelations among multi-view observations for the prediction task; this decoder operates only in the training phase so that the final model is implemented in an imputation-free manner. We validated the effectiveness of our method over the public MIMIC-III and PhysioNet challenge 2012 datasets by comparing with and outperforming the state-of-the-art methods in three downstream tasks i.e., prediction of the in-hospital mortality, prediction of the length of stay, and phenotyping. Moreover, we conduct a layer-wise relevance propagation (LRP) analysis based on case studies to highlight the explainability of the trained model.", "keywords": ["electronic health records", "bioinformatics", "irregular time series modeling", "deep learning", "self-attention"], "venue": "IEEE JOURNAL OF BIOMEDICAL AND HEALTH INFORMATICS", "authors": ["Lee, Yurim", "Jun, Eunji", "Choi, Jaehun", "Suk, Heung-Il"], "url": "https://doi.org/10.1109/JBHI.2022.3172549", "doi": "10.1109/JBHI.2022.3172549"}}
{"document_id": "ShenMa2018", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2018, "arxiv_id": null, "title": "End-to-End Time Series Imputation via Residual Short Paths", "abstract": "Time series imputation (replacing missing data) plays an important role in time series analysis due to missing values in real world data. How to recover missing values and model the underlying dynamic dependencies from incomplete time series remains a challenge. A recent work has found that residual networks help build very deep networks by leveraging short paths due to skip connections (Veit et al., 2016). Inspired by this, we observe that these short paths can model underlying correlations between missing items and their previous non-missing observations in a graph-like way. Hence, we propose an end-to-end imputation network with residual short paths, called Residual IMPutation LSTM (RIMP-LSTM), a flexible combination of residual short paths with graph-based temporal dependencies. We construct a residual sum unit (RSU), which enables RIMP-LSTM to make full use of previous revealed information to model incomplete time series and reduce the negative impact of missing values. Moreover, a switch unit is designed to detect the missing values and a new loss function is then developed to train our model with time series in the presence of missing values in an end-to-end way, which also allows simultaneous imputation and prediction. Extensive empirical comparisons with other competitive imputation approaches over several synthetic and real world time series with various rates of missing data verify the superiority of our model.", "keywords": ["time series imputation", "lstms", "end to end learning"], "venue": "Proceedings of Machine Learning Research (ACML 2018)", "authors": ["Shen, Lifeng", "Qianli", "Li, Sen"], "url": null, "doi": null}}
{"document_id": "SongRajan2018", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2018, "arxiv_id": null, "title": "Attend and Diagnose: Clinical Time Series Analysis Using Attention Models", "abstract": "With widespread adoption of electronic health records, there is an increased emphasis for predictive models that can effectively deal with clinical time-series data. Powered by Recurrent Neural Network (RNN) architectures with Long Short-Term Memory (LSTM) units, deep neural networks have achieved state-of-the-art results in several clinical prediction tasks. Despite the success of RNNs, its sequential nature prohibits parallelized computing, thus making it inefficient particularly when processing long sequences. Recently, architectures which are based solely on attention mechanisms have shown remarkable success in transduction tasks in NLP, while being computationally superior. In this paper, for the first time, we utilize attention models for clinical time-series modeling, thereby dispensing recurrence entirely. We develop the SAnD (Simply Attend and Diagnose) architecture, which employs a masked, self-attention mechanism, and uses positional encoding and dense interpolation strategies for incorporating temporal order. Furthermore, we develop a multi-task variant of SAnD to jointly infer models with multiple diagnosis tasks. Using the recent MIMIC-III benchmark datasets, we demonstrate that the proposed approach achieves state-of-the-art performance in all tasks, outperforming LSTM models and classical baselines with hand-engineered features.", "keywords": null, "venue": "The Thirty-Second AAAI Conference on Artificial Intelligence (AAAI-18)", "authors": ["Song, Huan", "Rajan, Deepta", "Thiagarajan, Jayaraman J.", "Spanias, Andreas"], "url": null, "doi": null}}
{"document_id": "JhinJo2021", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2021, "arxiv_id": null, "title": "ACE-NODE: Attentive Co-Evolving Neural Ordinary Differential Equations", "abstract": "Neural ordinary differential equations (NODEs) presented a new paradigm to construct (continuous-time) neural networks. While showing several good characteristics in terms of the number of parameters and the flexibility in constructing neural networks, they also have a couple of well-known limitations: i) theoretically NODEs learn homeomorphic mapping functions only, and ii) sometimes NODEs show numerical instability in solving integral problems. To handle this, many enhancements have been proposed. To our knowledge, however, integrating attention into NODEs has been overlooked for a while. To this end, we present a novel method of attentive dual co-evolving NODE (ACE-NODE): one main NODE for a downstream machine learning task and the other for providing attention to the main NODE. Our ACE-NODE supports both pair-wise and elementwise attention. In our experiments, our method outperforms existing NODE-based and non-NODE-based baselines in almost all cases by non-trivial margins.", "keywords": ["neural ordinary differential equations", "neural networks"], "venue": "Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD '21)", "authors": ["Jhin, Sheo Yon", "Jo, Minju", "Kong, Taeyong", "Jeon, Jinsung", "Park, Noseong"], "url": "https://doi.org/10.1145/3447548.3467419", "doi": "10.1145/3447548.3467419"}}
{"document_id": "ZhangZeman2022", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2022, "arxiv_id": "2110.05357v2", "title": "GRAPH-GUIDED NETWORK FOR IRREGULARLY SAMPLED MULTIVARIATE TIME SERIES", "abstract": "In many domains, including healthcare, biology, and climate science, time series are irregularly sampled with varying time intervals between successive readouts and different subsets of variables (sensors) observed at different time points. Here, we introduce RAINDROP, a graph neural network that embeds irregularly sampled and multivariate time series while also learning the dynamics of sensors purely from observational data. RAINDROP represents every sample as a separate sensor graph and models time-varying dependencies between sensors with a novel message passing operator. It estimates the latent sensor graph structure and leverages the structure together with nearby observations to predict misaligned readouts. This model can be interpreted as a graph neural network that sends messages over graphs that are optimized for capturing time-varying dependencies among sensors. We use RAINDROP to classify time series and interpret temporal dynamics on three healthcare and human activity datasets. RAINDROP outperforms state-of-the-art methods by up to 11.4% (absolute F1-score points), including techniques that deal with irregular sampling using fixed discretization and set functions. RAINDROP shows superiority in diverse setups, including challenging leave-sensor-out settings.", "keywords": null, "venue": "ICLR 2022", "authors": ["Zhang, Xiang", "Zeman, Marko", "Tsiligkaridis, Theodoros", "Zitnik, Marinka"], "url": null, "doi": null}}
{"document_id": "HerreraKrach2021", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2021, "arxiv_id": null, "title": "NEURAL JUMP ORDINARY DIFFERENTIAL EQUATIONS: CONSISTENT CONTINUOUS-TIME PREDICTION AND FILTERING", "abstract": "Combinations of neural ODEs with recurrent neural networks (RNN), like GRU-ODE-Bayes or ODE-RNN are well suited to model irregularly observed time series. While those models outperform existing discrete-time approaches, no theoretical guarantees for their predictive capabilities are available. Assuming that the irregularly-sampled time series data originates from a continuous stochastic process, the L2-optimal online prediction is the conditional expectation given the currently available information. We introduce the Neural Jump ODE (NJ-ODE) that provides a data-driven approach to learn, continuously in time, the conditional expectation of a stochastic process. Our approach models the conditional expectation between two observations with a neural ODE and jumps whenever a new observation is made. We define a novel training framework, which allows us to prove theoretical guarantees for the first time. In particular, we show that the output of our model converges to the L2-optimal prediction. This can be interpreted as solution to a special filtering problem. We provide experiments showing that the theoretical results also hold empirically. Moreover, we experimentally show that our model outperforms the baselines in more complex learning tasks and give comparisons on real-world datasets.", "keywords": null, "venue": "ICLR 2021", "authors": ["Herrera, Calypso", "Krach, Florian", "Teichmann, Josef"], "url": null, "doi": null}}
{"document_id": "TashiroSong2021", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2021, "arxiv_id": null, "title": "CSDI: Conditional Score-based Diffusion Models for Probabilistic Time Series Imputation", "abstract": "The imputation of missing values in time series has many applications in healthcare and ﬁnance. While autoregressive models are natural candidates for time series imputation, score-based diffusion models have recently outperformed existing counterparts including autoregressive models in many tasks such as image generation and audio synthesis, and would be promising for time series imputation. In this paper, we propose Conditional Score-based Diffusion models for Imputation (CSDI), a novel time series imputation method that utilizes score-based diffusion models conditioned on observed data. Unlike existing score-based approaches, the conditional diffusion model is explicitly trained for imputation and can exploit correlations between observed values. On healthcare and environmental data, CSDI improves by 40-65% over existing probabilistic imputation methods on popular performance metrics. In addition, deterministic imputation by CSDI reduces the error by 5-20% compared to the state-of-the-art deterministic imputation methods. Furthermore, CSDI can also be applied to time series interpolation and probabilistic forecasting, and is competitive with existing baselines. The code is available at https://github.com/ermongroup/CSDI.", "keywords": null, "venue": "35th Conference on Neural Information Processing Systems (NeurIPS 2021)", "authors": ["Tashiro, Yusuke", "Song, Jiaming", "Song, Yang", "Ermon, Stefano"], "url": null, "doi": null}}
{"document_id": "XiaoGou2023", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2023, "arxiv_id": null, "title": "Imputation-based Time-Series Anomaly Detection with Conditional Weight-Incremental Diffusion Models", "abstract": "Existing anomaly detection models for time series are primarily trained with normal-point-dominant data and would become ineffective when anomalous points intensively occur in certain episodes. To solve this problem, we propose a new approach, called DiffAD, from the perspective of time series imputation. Unlike previous prediction- and reconstruction-based methods that adopt either partial or complete data as observed values for estimation, DiffAD uses a density ratio-based strategy to select normal observations flexibly that can easily adapt to the anomaly concentration scenarios. To alleviate the model bias problem in the presence of anomaly concentration, we design a new denoising diffusion-based imputation method to enhance the imputation performance of missing values with conditional weight-incremental diffusion, which can preserve the information of observed values and substantially improves data generation quality for stable anomaly detection. Besides, we customize a multi-scale state space model to capture the long-term dependencies across episodes with different anomaly patterns. Extensive experimental results on real-world datasets show that DiffAD performs better than state-of-the-art benchmarks.", "keywords": ["time series", "diffusion models", "state space model", "data imputation"], "venue": "Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD '23)", "authors": ["Xiao, Chunjing", "Gou, Zehua", "Tai, Wenxin", "Zhang, Kunpeng", "Zhou, Fan"], "url": "https://doi.org/10.1145/3580305.3599391", "doi": "10.1145/3580305.3599391"}}
{"document_id": "WangZhang2023", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2023, "arxiv_id": null, "title": "An Observed Value Consistent Diffusion Model for Imputing Missing Values in Multivariate Time Series", "abstract": "Missing value, which is common in multivariate time series, is the most important obstacle towards the utilization and interpretation of those data. Great efforts have been employed on how to accurately impute missing values in multivariate time series, and existing works either use deep learning networks to achieve deterministic imputations or aim at generating different plausible imputations by sampling multiple noises from a same distribution and then denoising them. However, these models either fall short of modeling the uncertainties of imputations due to their deterministic nature or perform poorly in terms of interpretability and imputation accuracy due to their ignorance of the correlations between the latent representations of both observed and missing values, which are parts of samples from a same distribution. To this end, in this paper, we explicitly take the correlations between observed and missing values into account, and theoretically re-derive the Evidence Lower BOund (ELBO) of conditional diffusion model in the scenario of multivariate time series imputation. Based on the newly derived ELBO, we further propose a novel multivariate imputation diffusion model (MIDM) which is equipped with novel noise sampling, adding and denoising mechanisms for multivariate time series imputation, and the series of newly designed technologies jointly ensure the involving of the consistency between observed and missing values. Extensive experiments on both the tasks of multivariate time series imputation and forecasting witness the superiority of our proposed MIDM model on generating conditional estimations.", "keywords": ["diffusion model", "conditional generation", "multivariate time series"], "venue": "KDD '23", "authors": ["Wang, Xu", "Zhang, Hongbo", "Wang, Pengkun", "Zhang, Yudong", "Wang, Binwu", "Zhou, Zhengyang", "Wang, Yang"], "url": "https://doi.org/10.1145/3580305.3599257", "doi": "10.1145/3580305.3599257"}}
{"document_id": "AlcarazStrodthoff2023", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2023, "arxiv_id": null, "title": "Diffusion-based Time Series Imputation and Forecasting with Structured State Space Models", "abstract": "The imputation of missing values represents a significant obstacle for many real-world data analysis pipelines. Here, we focus on time series data and put forward SSSD, an imputation model that relies on two emerging technologies, (conditional) diffusion models as state-of-the-art generative models and structured state space models as internal model architecture, which are particularly suited to capture long-term dependencies in time series data. We demonstrate that SSSD matches or even exceeds state-of-the-art probabilistic imputation and forecasting performance on a broad range of data sets and different missingness scenarios, including the challenging blackout-missing scenarios, where prior approaches failed to provide meaningful results.", "keywords": null, "venue": "Transactions on Machine Learning Research", "authors": ["Lopez Alcaraz, Juan Miguel", "Strodthoff, Nils"], "url": "https: // openreview. net/ forum? id= hHiIbk7ApW", "doi": null}}
{"document_id": "DuDai2016", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2016, "arxiv_id": null, "title": "Recurrent Marked Temporal Point Processes: Embedding Event History to Vector", "abstract": "Large volumes of event data are becoming increasingly available in a wide variety of applications, such as healthcare analytics, smart cities and social network analysis. The precise time interval or the exact distance between two events carries a great deal of information about the dynamics of the underlying systems. These characteristics make such data fundamentally different from independently and identically distributed data and time-series data where time and space are treated as indexes rather than random variables. Marked temporal point processes are the mathematical framework for modeling event data with covariates. However, typical point process models often make strong assumptions about the generative processes of the event data, which may or may not reflect the reality, and the specifically fixed parametric assumptions also have restricted the expressive power of the respective processes. Can we obtain a more expressive model of marked temporal point processes? How can we learn such a model from massive data? In this paper, we propose the Recurrent Marked Temporal Point Process (RMTPP) to simultaneously model the event timings and the markers. The key idea of our approach is to view the intensity function of a temporal point process as a nonlinear function of the history, and use a recurrent neural network to automatically learn a representation of influences from the event history. We develop an efficient stochastic gradient algorithm for learning the model parameters which can readily scale up to millions of events. Using both synthetic and real world datasets, we show that, in the case where the true models have parametric specifications, RMTPP can learn the dynamics of such models without the need to know the actual parametric forms; and in the case where the true models are unknown, RMTPP can also learn the dynamics and achieve better predictive performance than other parametric alternatives based on particular prior assumptions.", "keywords": ["marked temporal point process", "stochastic process", "recurrent neural network"], "venue": "KDD", "authors": ["Du, Nan", "Dai, Hanjun", "Trivedi, Rakshit", "Upadhyay, Utkarsh", "Gomez-Rodriguez, Manuel", "Song, Le"], "url": "http://dx.doi.org/10.1145/2939672.2939875", "doi": "10.1145/2939672.2939875"}}
{"document_id": "XiaoYan2017", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2017, "arxiv_id": null, "title": "Modeling the Intensity Function of Point Process via Recurrent Neural Networkss", "abstract": "Event sequence, asynchronously generated with random timestamp, is ubiquitous among applications. The precise and arbitrary timestamp can carry important clues about the underlying dynamics, and has lent the event data fundamentally different from the time-series whereby series is indexed with fixed and equal time interval. One expressive mathematical tool for modeling event is point process. The intensity functions of many point processes involve two components: the background and the effect by the history. Due to its inherent spontaneousness, the background can be treated as a time series while the other need to handle the history events. In this paper, we model the background by a Recurrent Neural Network (RNN) with its units aligned with time series indexes while the history effect is modeled by another RNN whose units are aligned with asynchronous events to capture the long-range dynamics. The whole model with event type and timestamp prediction output layers can be trained end-to-end. Our approach takes an RNN perspective to point process, and models its background and history effect. For utility, our method allows a black-box treatment for modeling the intensity which is often a pre-defined parametric form in point processes. Meanwhile end-to-end training opens the venue for reusing existing rich techniques in deep network for point process modeling. We apply our model to the predictive maintenance problem using a log dataset by more than 1000 ATMs from a global bank headquartered in North America.", "keywords": null, "venue": "Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence (AAAI-17)", "authors": ["Xiao, Shuai", "Yan, Junchi", "Yang, Xiaokang", "Zha, Hongyuan", "Chu, Stephen M."], "url": null, "doi": null}}
{"document_id": "MeiEisner2017", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2017, "arxiv_id": null, "title": "The Neural Hawkes Process: A Neurally Self-Modulating Multivariate Point Process", "abstract": "Many events occur in the world. Some event types are stochastically excited or inhibited—in the sense of having their probabilities elevated or decreased—by patterns in the sequence of previous events. Discovering such patterns can help us predict which type of event will happen next and when. We model streams of discrete events in continuous time, by constructing a neurally self-modulating multivariate point process in which the intensities of multiple event types evolve according to a novel continuous-time LSTM. This generative model allows past events to influence the future in complex and realistic ways, by conditioning future event intensities on the hidden state of a recurrent neural network that has consumed the stream of past events. Our model has desirable qualitative properties. It achieves competitive likelihood and predictive accuracy on real and synthetic datasets, including under missing-data conditions.", "keywords": null, "venue": "31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.", "authors": ["Mei, Hongyuan", "Eisner, Jason"], "url": null, "doi": null}}
{"document_id": "OmiUeda2019", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2019, "arxiv_id": null, "title": "Fully Neural Network based Model for General Temporal Point Processes", "abstract": "A temporal point process is a mathematical model for a time series of discrete\nevents, which covers various applications. Recently, recurrent neural network\n(RNN) based models have been developed for point processes and have been\nfound effective. RNN based models usually assume a specific functional form\nfor the time course of the intensity function of a point process (e.g., exponentially\ndecreasing or increasing with the time since the most recent event). However, such\nan assumption can restrict the expressive power of the model. We herein propose a\nnovel RNN based model in which the time course of the intensity function is represented in a general manner. In our approach, we first model the integral of the\nintensity function using a feedforward neural network and then obtain the intensity\nfunction as its derivative. This approach enables us to both obtain a flexible model\nof the intensity function and exactly evaluate the log-likelihood function, which\ncontains the integral of the intensity function, without any numerical approximations. Our model achieves competitive or superior performances compared to the\nprevious state-of-the-art methods for both synthetic and real datasets.", "keywords": null, "venue": "33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada.", "authors": ["Omi, Takahiro", "Ueda, Naonori", "Aihara, Kazuyuki"], "url": null, "doi": null}}
{"document_id": "JiaBenson2019", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2019, "arxiv_id": null, "title": "Neural Jump Stochastic Differential Equations", "abstract": "Many time series are effectively generated by a combination of deterministic\ncontinuous ﬂows along with discrete jumps sparked by stochastic events. However,\nwe usually do not have the equation of motion describing the ﬂows, or how they are\naffected by jumps. To this end, we introduce Neural Jump Stochastic Differential\nEquations that provide a data-driven approach to learn continuous and discrete\ndynamic behavior, i.e., hybrid systems that both ﬂow and jump. Our approach\nextends the framework of Neural Ordinary Differential Equations with a stochastic\nprocess term that models discrete events. We then model temporal point processes\nwith a piecewise-continuous latent trajectory, where the discontinuities are caused\nby stochastic events whose conditional intensity depends on the latent state. We\ndemonstrate the predictive capabilities of our model on a range of synthetic and\nreal-world marked point process datasets, including classical point processes (such\nas Hawkes processes), awards on Stack Overﬂow, medical records, and earthquake\nmonitoring.", "keywords": null, "venue": "33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada.", "authors": ["Jia, Junteng", "Benson, Austin R."], "url": null, "doi": null}}
{"document_id": "BeckerPandya2019", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2019, "arxiv_id": null, "title": "Recurrent Kalman Networks: Factorized Inference in High-Dimensional Deep Feature Spaces", "abstract": "In order to integrate uncertainty estimates into deep time-series modelling, Kalman Filters (KFs) (Kalman et al., 1960) have been integrated with deep learning models, however, such approaches typically rely on approximate inference techniques such as variational inference which makes learning more complex and often less scalable due to approximation errors. We propose a new deep approach to Kalman filtering which can be learned directly in an end-to-end manner using backpropagation without additional approximations. Our approach uses a high-dimensional factorized latent state representation for which the Kalman updates simplify to scalar operations and thus avoids hard to backpropagate, computationally heavy and potentially unstable matrix inversions. Moreover, we use locally linear dynamic models to efficiently propagate the latent state to the next time step. The resulting network architecture, which we call Recurrent Kalman Network (RKN), can be used for any time-series data, similar to a LSTM (Hochreiter & Schmidhuber, 1997) but uses an explicit representation of uncertainty. As shown by our experiments, the RKN obtains much more accurate uncertainty estimates than an LSTM or Gated Recurrent Units (GRUs) (Cho et al., 2014) while also showing a slightly improved prediction performance and outperforms various recent generative models on an image imputation task.", "keywords": null, "venue": "Proceedings of the 36th International Conference on Machine Learning (PMLR)", "authors": ["Becker, Philipp", "Pandya, Harit", "Gebhardt, Gregor", "Zhao, Cheng", "Taylor, James", "Neumann, Gerhard"], "url": null, "doi": null}}
{"document_id": "Zuo2020", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2020, "arxiv_id": null, "title": "Transformer Hawkes Process", "abstract": "Modern data acquisition routinely produce massive amounts of event sequence data in various domains, such as social media, healthcare, and financial markets. These data often exhibit complicated short-term and long-term temporal dependencies. However, most of the existing recurrent neural network based point process models fail to capture such dependencies, and yield unreliable prediction performance. To address this issue, we propose a Transformer Hawkes Process (THP) model, which leverages the self-attention mechanism to capture long-term dependencies and meanwhile enjoys computational efficiency. Numerical experiments on various datasets show that THP outperforms existing models in terms of both likelihood and event prediction accuracy by a notable margin. Moreover, THP is quite general and can incorporate additional structural knowledge. We provide a concrete example, where THP achieves improved prediction performance for learning multiple point processes when incorporating their relational information.", "keywords": null, "venue": "Proceedings of the 37th International Conference on Machine Learning, PMLR 119", "authors": ["Zuo, Simiao", "Jiang, Haoming", "Li, Zichong", "Zhao, Tuo", "Zha, Hongyuan"], "url": null, "doi": null}}
{"document_id": "ZhangLipani2020", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2020, "arxiv_id": null, "title": "Self-Attentive Hawkes Process", "abstract": "Capturing the occurrence dynamics is crucial to predicting which type of events will happen next and when. A common method to do this is through Hawkes processes. To enhance their capacity, recurrent neural networks (RNNs) have been incorporated due to RNNs' successes in processing sequential data such as languages. Recent evidence suggests that self-attention is more competent than RNNs in dealing with languages. However, we are unaware of the effectiveness of self-attention in the context of Hawkes processes. This study aims to fill the gap by designing a self-attentive Hawkes process (SAHP). SAHP employs self-attention to summarise the influence of history events and compute the probability of the next event. One deficit of the conventional self-attention, when applied to event sequences, is that its positional encoding only considers the order of a sequence ignoring the time intervals between events. To overcome this deficit, we modify its encoding by translating time intervals into phase shifts of sinusoidal functions. Experiments on goodness-of-fit and prediction tasks show the improved capability of SAHP. Furthermore, SAHP is more interpretable than RNN-based counterparts because the learnt attention weights reveal contributions of one event type to the happening of another type. To the best of our knowledge, this is the first work that studies the effectiveness of self-attention in Hawkes processes.", "keywords": null, "venue": "Proceedings of the 37th International Conference on Machine Learning, Online, PMLR 119", "authors": ["Zhang, Qiang", "Lipani, Aldo", "Kirnap, Omer", "Yilmaz, Emine"], "url": null, "doi": null}}
{"document_id": "ShchurBilos2020", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2020, "arxiv_id": null, "title": "INTENSITY-FREE LEARNING OF TEMPORAL POINT PROCESSES", "abstract": "Temporal point processes are the dominant paradigm for modeling sequences of events happening at irregular intervals. The standard way of learning in such models is by estimating the conditional intensity function. However, parameterizing the intensity function usually incurs several trade-offs. We show how to overcome the limitations of intensity-based approaches by directly modeling the conditional distribution of inter-event times. We draw on the literature on normalizing flows to design models that are flexible and efficient. We additionally propose a simple mixture model that matches the flexibility of flow-based models, but also permits sampling and computing moments in closed form. The proposed models achieve state-of-the-art performance in standard prediction tasks and are suitable for novel applications, such as learning sequence embeddings and imputing missing data.", "keywords": null, "venue": "ICLR 2020", "authors": ["Shchur, Oleksandr", "Biloš, Marin", "Günnemann, Stephan"], "url": "https://github.com/shchur/ifl-tpp", "doi": null}}
{"document_id": "DengChang2020", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2020, "arxiv_id": null, "title": "Modeling Continuous Stochastic Processes with Dynamic Normalizing Flows", "abstract": "Normalizing flows transform a simple base distribution into a complex target distribution and have proved to be powerful models for data generation and density estimation. In this work, we propose a novel type of normalizing flow driven by a differential deformation of the Wiener process. As a result, we obtain a rich time series model whose observable process inherits many of the appealing properties of its base process, such as efficient computation of likelihoods and marginals. Furthermore, our continuous treatment provides a natural framework for irregular time series with an independent arrival process, including straightforward interpolation. We illustrate the desirable properties of the proposed model on popular stochastic processes and demonstrate its superior flexibility to variational RNN and latent ODE baselines in a series of experiments on synthetic and real-world data.", "keywords": null, "venue": "34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.", "authors": ["Deng, Ruizhi", "Chang, Bo", "Brubaker, Marcus A.", "Mori, Greg", "Lehrmann, Andreas M."], "url": null, "doi": null}}
{"document_id": "BilosSommer2021", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2021, "arxiv_id": null, "title": "Neural Flows: Efficient Alternative to Neural ODEs", "abstract": "Neural ordinary differential equations describe how values change in time. This is the reason why they gained importance in modeling sequential data, especially when the observations are made at irregular intervals. In this paper we propose an alternative by directly modeling the solution curves — the flow of an ODE — with a neural network. This immediately eliminates the need for expensive numerical solvers while still maintaining the modeling capability of neural ODEs. We propose several flow architectures suitable for different applications by establishing precise conditions on when a function defines a valid flow. Apart from computational efficiency, we also provide empirical evidence of favorable generalization performance via applications in time series modeling, forecasting, and density estimation.", "keywords": null, "venue": "NeurIPS (35th Conference on Neural Information Processing Systems)", "authors": ["Biloš, Marin", "Sommer, Johanna", "Rangapuram, Syama Sundar", "Januschowski, Tim", "Günnemann, Stephan"], "url": null, "doi": null}}
{"document_id": "DengBrubaker2021", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2021, "arxiv_id": null, "title": "Continuous Latent Process Flows", "abstract": "Partial observations of continuous time-series dynamics at arbitrary time stamps exist in many disciplines. Fitting this type of data using statistical models with continuous dynamics is not only promising at an intuitive level but also has practical benefits, including the ability to generate continuous trajectories and to perform inference on previously unseen time stamps. Despite exciting progress in this area, the existing models still face challenges in terms of their representation power and the quality of their variational approximations. We tackle these challenges with continuous latent process flows (CLPF), a principled architecture decoding continuous latent processes into continuous observable processes using a time-dependent normalizing flow driven by a stochastic differential equation. To optimize our model using maximum likelihood, we propose a novel piecewise construction of a variational posterior process and derive the corresponding variational lower bound using importance weighting of trajectories. An ablation study demonstrates the effectiveness of our contributions and comparisons to state-of-the-art baselines show our model's favourable performance on both synthetic and real-world data.", "keywords": null, "venue": "35th Conference on Neural Information Processing Systems (NeurIPS 2021)", "authors": ["Deng, Ruizhi", "Brubaker, Marcus A.", "Mori, Greg", "Lehrmann, Andreas M."], "url": null, "doi": null}}
{"document_id": "Schirmer2022", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2022, "arxiv_id": null, "title": "Modeling Irregular Time Series with Continuous Recurrent Units", "abstract": "Recurrent neural networks (RNNs) are a popular choice for modeling sequential data. Modern RNN architectures assume constant time-intervals between observations. However, in many datasets (e.g. medical records) observation times are irregular and can carry important information. To address this challenge, we propose continuous recurrent units (CRUs) – a neural architecture that can naturally handle irregular intervals between observations. The CRU assumes a hidden state, which evolves according to a linear stochastic differential equation and is integrated into an encoder-decoder framework. The recursive computations of the CRU can be derived using the continuous-discrete Kalman filter and are in closed form. The resulting recurrent architecture has temporal continuity between hidden states and a gating mechanism that can optimally integrate noisy observations. We derive an efficient parameterization scheme for the CRU that leads to a fast implementation f-CRU. We empirically study the CRU on a number of challenging datasets and find that it can interpolate irregular time series better than methods based on neural ordinary differential equations.", "keywords": null, "venue": "Proceedings of the 39th International Conference on Machine Learning (PMLR 162)", "authors": ["Schirmer, Mona", "Eltayeb, Mazin", "Lessmann, Stefan", "Rudolph, Maja"], "url": null, "doi": null}}
{"document_id": "Smith2023", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2023, "arxiv_id": null, "title": "SIMPLIFIED STATE SPACE LAYERS FOR SEQUENCE MODELING", "abstract": "Models using structured state space sequence (S4) layers have achieved state-of-the-art performance on long-range sequence modeling tasks. An S4 layer combines linear state space models (SSMs), the HiPPO framework, and deep learning to achieve high performance. We build on the design of the S4 layer and introduce a new state space layer, the S5 layer. Whereas an S4 layer uses many independent single-input, single-output SSMs, the S5 layer uses one multi-input, multi-output SSM. We establish a connection between S5 and S4, and use this to develop the initialization and parameterization used by the S5 model. The result is a state space layer that can leverage efficient and widely implemented parallel scans, allowing S5 to match the computational efficiency of S4, while also achieving state-of-the-art performance on several long-range sequence modeling tasks. S5 averages 87.4% on the long range arena benchmark, and 98.5% on the most difficult Path-X task.", "keywords": null, "venue": "ICLR", "authors": ["Smith, Jimmy T. H.", "Warrington, Andrew", "Linderman, Scott W."], "url": null, "doi": null}}
{"document_id": "XiaoXu2025", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2025, "arxiv_id": "2402.02258", "title": "XTSFormer: Cross-Temporal-Scale Transformer for Irregular-Time Event Prediction in Clinical Applications", "abstract": "Adverse clinical events related to unsafe care are among the top ten causes of death in the U.S. Accurate modeling and prediction of clinical events from electronic health records (EHRs) play a crucial role in patient safety enhancement. An example is modeling de facto care pathways that characterize common step-by-step plans for treatment or care. However, clinical event data pose several unique challenges, including the irregularity of time intervals between consecutive events, the existence of cycles, periodicity, multi-scale event interactions, and the high computational costs associated with long event sequences. Existing neural temporal point processes (TPPs) methods do not effectively capture the multi-scale nature of event interactions, which is common in many real-world clinical applications. To address these issues, we propose the cross-temporal-scale transformer (XTSFormer), specifically designed for irregularly timed event data. Our model consists of two vital components: a novel Feature-based Cycle-aware Time Positional Encoding (FCPE) that adeptly captures the cyclical nature of time, and a hierarchical multi-scale temporal attention mechanism, where different temporal scales are determined by a bottom-up clustering approach. Extensive experiments on several real-world EHR datasets show that our XTSFormer outperforms multiple baseline methods.", "keywords": null, "venue": "The Thirty-Ninth AAAI Conference on Artificial Intelligence (AAAI-25)", "authors": ["Xiao, Tingsong", "Xu, Zelin", "He, Wenchong", "Xiao, Zhengkun", "Zhang, Yupu", "Liu, Zibo", "Chen, Shigang", "Thai, My T.", "Bian, Jiang", "Rashidi, Parisa", "Jiang, Zhe"], "url": "https://arxiv.org/abs/2402.02258", "doi": null}}
{"document_id": "Xu2019", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2019, "arxiv_id": null, "title": "Self-attention with Functional Time Representation Learning", "abstract": "Sequential modelling with self-attention has achieved cutting edge performances in natural language processing. With advantages in model flexibility, computation complexity and interpretability, self-attention is gradually becoming a key component in event sequence models. However, like most other sequence models, self-attention does not account for the time span between events and thus captures sequential signals rather than temporal patterns. Without relying on recurrent network structures, self-attention recognizes event orderings via positional encoding. To bridge the gap between modelling time-independent and time-dependent event sequence, we introduce a functional feature map that embeds time span into high-dimensional spaces. By constructing the associated translation-invariant time kernel function, we reveal the functional forms of the feature map under classic functional function analysis results, namely Bochner’s Theorem and Mercer’s Theorem. We propose several models to learn the functional time representation and the interactions with event representation. These methods are evaluated on real-world datasets under various continuous-time event sequence prediction tasks. The experiments reveal that the proposed methods compare favorably to baseline models while also capturing useful time-event interactions.", "keywords": null, "venue": "33rd Conference on Neural Information Processing Systems (NeurIPS 2019)", "authors": ["Xu, Da", "Ruan, Chuanwei", "Kumar, Sushant", "Korpeoglu, Evren", "Achan, Kannan"], "url": null, "doi": null}}
{"document_id": "BrouwerSimm2019", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2019, "arxiv_id": null, "title": "GRU-ODE-Bayes: Continuous modeling of sporadically-observed time series", "abstract": "Modeling real-world multidimensional time series can be particularly challenging when these are sporadically observed (i.e., sampling is irregular both in time and across dimensions)—such as in the case of clinical patient data. To address these challenges, we propose (1) a continuous-time version of the Gated Recurrent Unit, building upon the recent Neural Ordinary Differential Equations (Chen et al., 2018), and (2) a Bayesian update network that processes the sporadic observations. We bring these two ideas together in our GRU-ODE-Bayes method. We then demonstrate that the proposed method encodes a continuity prior for the latent process and that it can exactly represent the Fokker-Planck dynamics of complex processes driven by a multidimensional stochastic differential equation. Additionally, empirical evaluation shows that our method outperforms the state of the art on both synthetic data and real-world data with applications in healthcare and climate forecast. What is more, the continuity prior is shown to be well suited for low number of samples settings.", "keywords": null, "venue": "33rd Conference on Neural Information Processing Systems (NeurIPS 2019)", "authors": ["De Brouwer, Edward", "Simm, Jaak", "Arany, Adam", "Moreau, Yves"], "url": null, "doi": null}}
{"document_id": "Ma2022", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2022, "arxiv_id": null, "title": "Non-stationary Time-aware Kernelized Attention for Temporal Event Prediction", "abstract": "Modeling sequential data is essential to many applications such as natural language processing, recommendation systems, time series predictions, anomaly detection, etc. When processing sequential data, one of the critical issues is how to capture the temporal-correlation among events. Though prevalent and effective in many applications, conventional approaches such as RNNs and Transformers, struggle with handling the non-stationary characteristics (i.e., such temporal-correlation among events would change over time), which is indeed encountered in many real-world scenarios. In this paper, we present a non-stationary time-aware kernelized attention approach for input sequences of neural networks. By constructing the Generalized Spectral Mixture Kernel (GSMK), and integrating it to the attention mechanism, we mathematically reveal its representation capability in terms of the time-dependent temporal-correlation. Following that, a novel neural network structure is proposed, which would enable us to encode both stationary and non-stationary time event series. Finally, we demonstrate the performance of the proposed method on both synthetic data which presents the theoretical insights, and a variety of real-world datasets which shows its competitive performance against related work.", "keywords": ["temporal event prediction", "kernelized attention", "non-stationarity"], "venue": "Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD '22)", "authors": ["Yu", "Liu, Zhining", "Zhuang, Chenyi", "Tan, Yize", "Dong, Yi", "Zhong, Wenliang", "Gu, Jinjie"], "url": "https://doi.org/10.1145/3534678.3539470", "doi": "10.1145/3534678.3539470"}}
{"document_id": "BaytasXiao2017", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2017, "arxiv_id": null, "title": "Patient Subtyping via Time-Aware LSTM Networks", "abstract": "In the study of various diseases, heterogeneity among patients usually leads to different progression paterns and may require different types of therapeutic intervention. Therefore, it is important to study patient subtyping, which is grouping of patients into disease characterizing subtypes. Subtyping from complex patient data is challenging because of the information heterogeneity and temporal dynamics. Long-Short Term Memory (LSTM) has been successfully used in many domains for processing sequential data, and recently applied for analyzing longitudinal patient records. The LSTM units are designed to handle data with constant elapsed times between consecutive elements of a sequence. Given that time lapse between successive elements in patient records can vary from days to months, the design of traditional LSTM may lead to suboptimal performance. In this paper, we propose a novel LSTM unit called Time-Aware LSTM (T-LSTM) to handle irregular time intervals in longitudinal patient records. We learn a subspace decomposition of the cell memory which enables time decay to discount the memory content according to the elapsed time. We propose a patient subtyping model that leverages the proposed T-LSTM in an auto-encoder to learn a powerful single representation for sequential records of patients, which are then used to cluster patients into clinical subtypes. Experiments on synthetic and real world datasets show that the proposed T-LSTM architecture captures the underlying structures in the sequences with time irregularities.", "keywords": ["patient subtyping", "recurrent neural network", "long-short term memory"], "venue": "KDD'17", "authors": ["Baytas, Inci M.", "Xiao, Cao", "Zhang, Xi", "Wang, Fei", "Jain, Anil K.", "Zhou, Jiayu"], "url": "http://dx.doi.org/10.1145/3097983.3097997", "doi": "10.1145/3097983.3097997"}}
{"document_id": "YoonZame2018", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2019, "arxiv_id": null, "title": "Estimating Missing Data in Temporal Data Streams Using Multi-Directional Recurrent Neural Networks", "abstract": "Missing data is a ubiquitous problem. It is especially challenging in medical settings because many streams of measurements are collected at different—and often irregular—times. Accurate estimation of the missing measurements is critical for many reasons, including diagnosis, prognosis, and treatment. Existing methods address this estimation problem by interpolating within data streams or imputing across data streams (both of which ignore important information) or ignoring the temporal aspect of the data and imposing strong assumptions about the nature of the data-generating process and/or the pattern of missing data (both of which are especially problematic for medical data). We propose a new approach, based on a novel deep learning architecture that we call a Multi-directional Recurrent Neural Network that interpolates within data streams and imputes across data streams. We demonstrate the power of our approach by applying it to five real-world medical datasets. We show that it provides dramatically improved estimation of missing measurements in comparison to 11 state-of-the-art benchmarks (including Spline and Cubic Interpolations, MICE, MissForest, matrix completion, and several RNN methods); typical improvements in Root Mean Squared Error are between 35%–50%. Additional experiments based on the same five datasets demonstrate that the improvements provided by our method are extremely robust.", "keywords": ["missing data", "temporal data streams", "imputation", "recurrent neural nets"], "venue": "IEEE Transactions on Biomedical Engineering", "authors": ["Yoon, Jinsung", "Zame, William R.", "Van Der Schaar, Mihaela"], "url": null, "doi": "10.1109/TBME.2018.2874712"}}
{"document_id": "CaoWang2018", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2018, "arxiv_id": null, "title": "BRITS: Bidirectional Recurrent Imputation for Time Series", "abstract": "Time series are ubiquitous in many classification/regression applications. However, the time series data in real applications may contain many missing values. Hence, given multiple (possibly correlated) time series data, it is important to fill in missing values and at the same time to predict their class labels. Existing imputation methods often impose strong assumptions of the underlying data generating process, such as linear dynamics in the state space. In this paper, we propose a novel method, called BRITS, based on recurrent neural networks for missing value imputation in time series data. Our proposed method directly learns the missing values in a bidirectional recurrent dynamical system, without any specific assumption. The imputed values are treated as variables of RNN graph and can be effectively updated during backpropagation. BRITS has three advantages: (a) it can handle multiple correlated missing values in time series; (b) it generalizes to time series with nonlinear dynamics underlying; (c) it provides a data-driven imputation procedure and applies to general settings with missing data. We evaluate our model on three real-world datasets, including an air quality dataset, a health-care dataset, and a localization dataset for human activity. Experiments show that our model outperforms the state-of-the-art methods in both imputation and classification/regression.", "keywords": null, "venue": "32nd Conference on Neural Information Processing Systems (NeurIPS 2018)", "authors": ["Cao, Wei", "Wang, Dong", "Li, Jian", "Zhou, Hao", "Li, Yitan", "Li, Lei"], "url": null, "doi": null}}
{"document_id": "SuoZhong2020", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2020, "arxiv_id": null, "title": "GLIMA: Global and Local Time Series Imputation with Multi-directional Attention Learning", "abstract": "Missing data, which commonly appears in multivariate time series, has been widely recognized as a key challenge in time series analysis. Many commonly used imputation methods either ignore the temporal dependencies of time series data, or do not adequately utilize the relationships among variables. State-of-the-art methods on time series imputation are built on Recurrent Neural Networks (RNNs), which utilize the historical information to estimate current values sequentially. However, RNNs rely heavily on the output of nearby timestamps, which may lead to important information lost for long sequences. Moreover, individual variables typically present different dynamics and missingness patterns, which is neglected by the global RNN hidden states. In this paper, we propose an imputation framework to learn both global and local dependencies of multivariate time series, as well as a multi-dimensional self-attention to learn capture distant correlations across both time and feature. Extensive experiments show that the proposed framework outperforms the state-of-the-art methods in the imputation task, and benefits the downstream task.", "keywords": ["time series", "missing data", "recurrent imputation", "self-attention"], "venue": "2020 IEEE International Conference on Big Data (Big Data)", "authors": ["Suo, Qiuling", "Zhong, Weida", "Xun, Guangxu", "Sun, Jianhui", "Chen, Changyou", "Zhang, Aidong"], "url": "https://doi.org/10.1109/BigData50022.2020.9378408", "doi": "10.1109/BigData50022.2020.9378408"}}
{"document_id": "YildizKoc2022", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2022, "arxiv_id": null, "title": "Multivariate Time Series Imputation With Transformers", "abstract": "Processing time series with missing segments is a fundamental challenge that puts obstacles to advanced analysis in various disciplines such as engineering, medicine, and economics. One of the remedies is imputation to fill the missing values based on observed values properly without undermining performance. We propose the Multivariate Time-Series Imputation with Transformers (MTSIT), a novel method that uses transformer architecture in an unsupervised manner for missing value imputation. Unlike the existing transformer architectures, this model only uses the encoder part of the transformer due to computational benefits. Crucially, MTSIT trains the autoencoder by jointly reconstructing and imputing stochastically-masked inputs via an objective designed for multivariate time-series data. The trained autoencoder is then evaluated for imputing both simulated and real missing values. Experiments show that MTSIT outperforms state-of-the-art imputation methods over benchmark datasets.", "keywords": ["deep learning", "imputation", "multivariate time series", "time series", "transformer", "unsupervised learning"], "venue": "IEEE Signal Processing Letters", "authors": ["Yıldız, A. Yarkın", "Koç, Emirhan", "Koç, Aykut"], "url": "https://doi.org/10.1109/LSP.2022.3224880", "doi": "10.1109/LSP.2022.3224880"}}
{"document_id": "DuCote2023", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2023, "arxiv_id": null, "title": "SAITS: Self-attention-based imputation for time series", "abstract": "Missing data in time series is a pervasive problem that puts obstacles in the way of advanced analysis. A popular solution is imputation, where the fundamental challenge is to determine what values should be filled in. This paper proposes SAITS, a novel method based on the self-attention mechanism for missing value imputation in multivariate time series. Trained by a joint-optimization approach, SAITS learns missing values from a weighted combination of two diagonally-masked self-attention (DMSA) blocks. DMSA explicitly captures both the temporal dependencies and feature correlations between time steps, which improves imputation accuracy and training speed. Meanwhile, the weighted-combination design enables SAITS to dynamically assign weights to the learned representations from two DMSA blocks according to the attention map and the missingness information. Extensive experiments quantitatively and qualitatively demonstrate that SAITS outperforms the state-of-the-art methods on the time-series imputation task efficiently and reveal SAITS’ potential to improve the learning performance of pattern recognition models on incomplete time-series data from the real world.", "keywords": ["time series", "missing values", "imputation model", "self-attention", "neural network"], "venue": "Expert Systems With Applications", "authors": ["Du, Wenjie", "Côté, David", "Liu, Yan"], "url": "https://doi.org/10.1016/j.eswa.2023.119619", "doi": "10.1016/j.eswa.2023.119619"}}
{"document_id": "JhinLee2023", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2023, "arxiv_id": "2306.15489v3", "title": "Precursor-of-Anomaly Detection for Irregular Time Series", "abstract": "Anomaly detection is an important field that aims to identify unexpected patterns or data points, and it is closely related to many real-world problems, particularly to applications in finance, manufacturing, cyber security, and so on. While anomaly detection has been studied extensively in various fields, detecting future anomalies before they occur remains an unexplored territory. In this paper, we present a novel type of anomaly detection, called Precursor-of-Anomaly (PoA) detection. Unlike conventional anomaly detection, which focuses on determining whether a given time series observation is an anomaly or not, PoA detection aims to detect future anomalies before they happen. To solve both problems at the same time, we present a neural controlled differential equation-based neural network and its multi-task learning algorithm. We conduct experiments using 17 baselines and 3 datasets, including regular and irregular time series, and demonstrate that our presented method outperforms the baselines in almost all cases. Our ablation studies also indicate that the multitasking training method significantly enhances the overall performance for both anomaly and PoA detection.", "keywords": ["time-series", "anomaly detection", "multi-task learning"], "venue": "Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD '23)", "authors": ["Jhin, Sheo Yon", "Lee, Jaehoon", "Park, Noseong"], "url": "https://doi.org/10.1145/3580305.3599469", "doi": "10.1145/3580305.3599469"}}
{"document_id": "ShanLi2023", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2023, "arxiv_id": null, "title": "NRTSI: NON-RECURRENT TIME SERIES IMPUTATION", "abstract": "Time series imputation is a fundamental task in understanding sequential data. Existing methods either rely on recurrent models that suffer heavily from error compounding or fail to exploit the hierarchical information of temporal data, both of which degrade performance severely with sparsely observed data. In this work, we reformulate time series as sets and propose a novel non-recurrent imputation model, Non-Recurrent Time Series Imputation (NRTSI), that does not impose any recurrent structures. Taking advantage of the set formulation, we design a principled and efficient hierarchical imputation procedure. In addition, NRTSI can perform multiple-mode stochastic imputation, directly handle irregularly-sampled time series, and handle data with partially observed dimensions. Empirically, we show that NRTSI achieves state-of-the-art performance on multiple benchmarks.", "keywords": ["time series", "non-recurrent models", "set modeling", "transformer", "hierarchical methods"], "venue": "ICASSP 2023", "authors": ["Shan, Siyuan", "Li, Yang", "Oliva, Junier B."], "url": "https://github.com/lupalab/NRTSI", "doi": "10.1109/ICASSP49357.2023.10095054"}}
{"document_id": "YueWang2022", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2022, "arxiv_id": null, "title": "TS2Vec: Towards Universal Representation of Time Series", "abstract": "This paper presents TS2Vec, a universal framework for learning representations of time series in an arbitrary semantic level. Unlike existing methods, TS2Vec performs contrastive learning in a hierarchical way over augmented context views, which enables a robust contextual representation for each timestamp. Furthermore, to obtain the representation of an arbitrary sub-sequence in the time series, we can apply a simple aggregation over the representations of corresponding timestamps. We conduct extensive experiments on time series classification tasks to evaluate the quality of time series representations. As a result, TS2Vec achieves significant improvement over existing SOTAs of unsupervised time series representation on 125 UCR datasets and 29 UEA datasets. The learned timestamp-level representations also achieve superior results in time series forecasting and anomaly detection tasks. A linear regression trained on top of the learned representations outperforms previous SOTAs of time series forecasting. Furthermore, we present a simple way to apply the learned representations for unsupervised anomaly detection, which establishes SOTA results in the literature. The source code is publicly available at https://github.com/yuezhihan/ts2vec.", "keywords": null, "venue": "The Thirty-Sixth AAAI Conference on Artificial Intelligence (AAAI-22)", "authors": ["Yue, Zhihan", "Wang, Yujing", "Duan, Juanyong", "Yang, Tianmeng", "Huang, Congrui", "Tong, Yunhai", "Xu, Bixiong"], "url": "https://github.com/yuezhihan/ts2vec", "doi": null}}
{"document_id": "ChoiBahadori2016", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2016, "arxiv_id": null, "title": "RETAIN: An Interpretable Predictive Model for Healthcare using Reverse Time Attention Mechanism", "abstract": "Accuracy and interpretability are two dominant features of successful predictive models. Typically, a choice must be made in favor of complex black box models such as recurrent neural networks (RNN) for accuracy versus less accurate but more interpretable traditional models such as logistic regression. This tradeoff poses challenges in medicine where both accuracy and interpretability are important. We addressed this challenge by developing the REverse Time AttentIoN model (RETAIN) for application to Electronic Health Records (EHR) data. RETAIN achieves high accuracy while remaining clinically interpretable and is based on a two-level neural attention model that detects influential past visits and significant clinical variables within those visits (e.g. key diagnoses). RETAIN mimics physician practice by attending the EHR data in a reverse time order so that recent clinical visits are likely to receive higher attention. RETAIN was tested on a large health system EHR dataset with 14 million visits completed by 263K patients over an 8 year period and demonstrated predictive accuracy and computational scalability comparable to state-of-the-art methods such as RNN, and ease of interpretability comparable to traditional models.", "keywords": null, "venue": "Neural Information Processing Systems (NIPS 2016)", "authors": ["Choi, Edward", "Bahadori, Mohammad Taha", "Kulas, Joshua A.", "Schuetz, Andy", "Stewart, Walter F.", "Sun, Jimeng"], "url": null, "doi": null}}
{"document_id": "LiptonKale2016", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2016, "arxiv_id": null, "title": "Modeling Missing Data in Clinical Time Series with RNNs", "abstract": "We demonstrate a simple strategy to cope with missing data in sequential inputs, addressing the task of multilabel classiﬁcation of diagnoses given clinical time series. Collected from the pediatric intensive care unit (PICU) at Children’s Hospital Los Angeles, our data consists of multivariate time series of observations. The measurements are irregularly spaced, leading to missingness patterns in temporally discretized sequences. While these artifacts are typically handled by imputation, we achieve superior predictive performance by treating the artifacts as features. Unlike linear models, recurrent neural networks can realize this improvement using only simple binary indicators of missingness. For linear models, we show an alternative strategy to capture this signal. Training models on missingness patterns only, we show that for some diseases, what tests are run can as predictive as the results themselves.", "keywords": null, "venue": "Proceedings of Machine Learning for Healthcare 2016 (JMLR W&C Track Volume 56)", "authors": ["Lipton, Zachary C.", "Kale, David C.", "Wetzel, Randall"], "url": null, "doi": null}}
{"document_id": "PhamTran2016", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2016, "arxiv_id": null, "title": "DeepCare: A Deep Dynamic Memory Model for Predictive Medicine", "abstract": "Personalized predictive medicine necessitates modeling of patient illness and care processes, which inherently have long-term temporal dependencies. Healthcare observations, recorded in electronic medical records, are episodic and irregular in time. We introduce DeepCare, a deep dynamic neural network that reads medical records and predicts future medical outcomes. At the data level, DeepCare models patient health state trajectories with explicit memory of illness. Built on Long Short-Term Memory (LSTM), DeepCare introduces time parameterizations to handle irregular timing by moderating the forgetting and consolidation of illness memory. DeepCare also incorporates medical interventions that change the course of illness and shape future medical risk. Moving up to the health state level, historical and present health states are then aggregated through multiscale temporal pooling, before passing through a neural network that estimates future outcomes. We demonstrate the efficacy of DeepCare for disease progression modeling and readmission prediction in diabetes, a chronic disease with large economic burden. The results show improved modeling and risk prediction accuracy.", "keywords": null, "venue": "PAKDD 2016, Part II, LNAI 9652", "authors": ["Pham, Trang", "Tran, Truyen", "Phung, Dinh", "Venkatesh, Svetha"], "url": null, "doi": "10.1007/978-3-319-31750-2 3"}}
{"document_id": "Neil2016", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2016, "arxiv_id": null, "title": "Phased LSTM: Accelerating Recurrent Network Training for Long or Event-based Sequences", "abstract": "Recurrent Neural Networks (RNNs) have become the state-of-the-art choice for extracting patterns from temporal sequences. However, current RNN models are ill-suited to process irregularly sampled data triggered by events generated in continuous time by sensors or other neurons. Such data can occur, for example, when the input comes from novel event-driven artiﬁcial sensors that generate sparse, asynchronous streams of events or from multiple conventional sensors with different update intervals. In this work, we introduce the Phased LSTM model, which extends the LSTM unit by adding a new time gate. This gate is controlled by a parametrized oscillation with a frequency range that produces updates of the memory cell only during a small percentage of the cycle. Even with the sparse updates imposed by the oscillation, the Phased LSTM network achieves faster convergence than regular LSTMs on tasks which require learning of long sequences. The model naturally integrates inputs from sensors of arbitrary sampling rates, thereby opening new areas of investigation for processing asynchronous sensory events that carry timing information. It also greatly improves the performance of LSTMs in standard RNN applications, and does so with an order-of-magnitude fewer computes at runtime.", "keywords": null, "venue": "30th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain", "authors": ["Neil, Daniel", "Pfeiffer, Michael", "Liu, Shih-Chii"], "url": null, "doi": null}}
{"document_id": "MozerKazakov2017", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2017, "arxiv_id": "1710.04110v1", "title": "Discrete-Event Continuous-Time Recurrent Nets", "abstract": "We investigate recurrent neural network architectures for event-sequence processing. Event sequences, characterized by discrete observations stamped with continuous-valued times of occurrence, are challenging due to the potentially wide dynamic range of relevant time scales as well as interactions between time scales. We describe four forms of inductive bias that should benefit architectures for event sequences: temporal locality, position and scale homogeneity, and scale interdependence. We extend the popular gated recurrent unit (GRU) architecture to incorporate these biases via intrinsic temporal dynamics, obtaining a continuous-time GRU. The CT-GRU arises by interpreting the gates of a GRU as selecting a time scale of memory, and the CT-GRU generalizes the GRU by incorporating multiple time scales of memory and performing context-dependent selection of time scales for information storage and retrieval. Event time-stamps drive decay dynamics of the CT-GRU, whereas they serve as generic additional inputs to the GRU. Despite the very different manner in which the two models consider time, their performance on eleven data sets we examined is essentially identical. Our surprising results point both to the robustness of GRU and LSTM architectures for handling continuous time, and to the potency of incorporating continuous dynamics into neural architectures.", "keywords": null, "venue": null, "authors": ["Mozer, Michael C.", "Kazakov, Denis", "Lindsey, Robert V."], "url": null, "doi": null}}
{"document_id": "KimChi2018", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": null, "arxiv_id": null, "title": "Temporal Belief Memory: Imputing Missing Data during RNN Training", "abstract": "We propose a bio-inspired approach named Temporal Belief Memory (TBM) for handling missing data with recurrent neural networks (RNNs). When modeling irregularly observed temporal sequences, conventional RNNs generally ignore the real-time intervals between consecutive observations. TBM is a missing value imputation method that considers the time continuity and captures latent missing patterns based on irregular real time intervals of the inputs. We evaluate our TBM approach with real-world electronic health records (EHRs) consisting of 52,919 visits and 4,224,567 events on a task of early prediction of septic shock. We compare TBM against multiple baselines including both domain experts’ rules and the state-of-the-art missing data handling approach using both RNN and long short-term memory. The experimental results show that TBM outperforms all the competitive baseline approaches for the septic shock early prediction task.", "keywords": null, "venue": null, "authors": ["Kim, Yeo Jin", "Chi, Min"], "url": null, "doi": null}}
{"document_id": "ChePurushotham2018", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2018, "arxiv_id": null, "title": "Recurrent Neural Networks for Multivariate Time Series with Missing Values", "abstract": "Multivariate time series data in practical applications, such as health care, geoscience, and biology, are characterized by a variety of missing values. In time series prediction and other related tasks, it has been noted that missing values and their missing patterns are often correlated with the target labels, a.k.a., informative missingness. There is very limited work on exploiting the missing patterns for effective imputation and improving prediction performance. In this paper, we develop novel deep learning models, namely GRU-D, as one of the early attempts. GRU-D is based on Gated Recurrent Unit (GRU), a state-of-the-art recurrent neural network. It takes two representations of missing patterns, i.e., masking and time interval, and effectively incorporates them into a deep model architecture so that it not only captures the long-term temporal dependencies in time series, but also utilizes the missing patterns to achieve better prediction results. Experiments of time series classification tasks on real-world clinical datasets (MIMIC-III, PhysioNet) and synthetic datasets demonstrate that our models achieve state-of-the-art performance and provide useful insights for better understanding and utilization of missing values in time series analysis.", "keywords": null, "venue": "Scientific Reports", "authors": ["Che, Zhengping", "Purushotham, Sanjay", "Cho, Kyunghyun", "Sontag, David", "Liu, Yan"], "url": null, "doi": "10.1038/s41598-018-24271-9"}}
{"document_id": "ZhangYang2019", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2019, "arxiv_id": null, "title": "ATTAIN: Attention-based Time-Aware LSTM Networks for Disease Progression Modeling", "abstract": "Modeling patient disease progression using Electronic Health Records (EHRs) is critical to assist clinical decision making. Long-Short Term Memory (LSTM) is an effective model to handle sequential data, such as EHRs, but it encounters two major limitations when applied to EHRs: it is unable to interpret the prediction results and it ignores the irregular time intervals between consecutive events. To tackle these limitations, we propose an attention-based time-aware LSTM Networks (ATTAIN), to improve the interpretability of LSTM and to identify the critical previous events for current diagnosis by modeling the inherent time irregularity. We validate ATTAIN on modeling the progression of an extremely challenging disease, septic shock, by using real-world EHRs. Our results demonstrate that the proposed framework outperforms the state-of-the-art models such as RETAIN and T-LSTM. Also, the generated interpretative time-aware attention weights shed some light on the progression behaviors of septic shock.", "keywords": null, "venue": "Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence (IJCAI-19)", "authors": ["Zhang, Yuan", "Yang, Xi", "Ivy, Julie", "Chi, Min"], "url": null, "doi": null}}
{"document_id": "BahadoriLipton2019", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2019, "arxiv_id": "1904.12206v1", "title": "Temporal-Clustering Invariance in Irregular Healthcare Time Series", "abstract": "Electronic records contain sequences of events, some of which take place all at once in a single\nvisit, and others that are dispersed over multiple visits, each with a diﬀerent timestamp.\nWe postulate that ﬁne temporal detail, e.g., whether a series of blood tests are completed at\nonce or in rapid succession should not alter predictions based on this data. Motivated by this\nintuition, we propose models for analyzing sequences of multivariate clinical time series data\nthat are invariant to this temporal clustering. We propose an eﬃcient data augmentation\ntechnique that exploits the postulated temporal-clustering invariance to regularize deep\nneural networks optimized for several clinical prediction tasks. We introduce two techniques\nto temporally coarsen (downsample) irregular time series: (i) grouping the data points\nbased on regularly-spaced timestamps; and (ii) clustering them, yielding irregularly-paced\ntimestamps. Moreover, we propose a MultiResolution Ensemble (MRE) model, improving\npredictive accuracy by ensembling predictions based on inputs sequences transformed by\ndiﬀerent coarsening operators. Our experiments show that MRE improves the mAP on the\nbenchmark mortality prediction task from 51.53% to 53.92%.", "keywords": null, "venue": "arXiv", "authors": ["Bahadori, Mohammad Taha", "Lipton, Zachary Chase"], "url": null, "doi": null}}
{"document_id": "Rubanova2019", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2019, "arxiv_id": null, "title": "Latent ODEs for Irregularly-Sampled Time Series", "abstract": "Time series with non-uniform intervals occur in many applications, and are dif-\nﬁcult to model using standard recurrent neural networks (RNNs). We generalize\nRNNs to have continuous-time hidden dynamics deﬁned by ordinary differential\nequations (ODEs), a model we call ODE-RNNs. Furthermore, we use ODE-RNNs\nto replace the recognition network of the recently-proposed Latent ODE model.\nBoth ODE-RNNs and Latent ODEs can naturally handle arbitrary time gaps be-\ntween observations, and can explicitly model the probability of observation times\nusing Poisson processes. We show experimentally that these ODE-based models\noutperform their RNN-based counterparts on irregularly-sampled data.", "keywords": null, "venue": "33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada.", "authors": ["Rubanova, Yulia", "Chen, Ricky T. Q.", "Duvenaud, David"], "url": null, "doi": null}}
{"document_id": "Horn2020", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2020, "arxiv_id": null, "title": "Set Functions for Time Series", "abstract": "Despite the eminent successes of deep neural networks, many architectures are often hard to transfer to irregularly-sampled and asynchronous time series that commonly occur in real-world datasets, especially in healthcare applications. This paper proposes a novel approach for classifying irregularly-sampled time series with un-aligned measurements, focusing on high scalability and data efficiency. Our method SeFT (Set Functions for Time Series) is based on recent advances in differentiable set function learning, extremely parallelizable with a beneficial memory footprint, thus scaling well to large datasets of long time series and online monitoring scenarios. Furthermore, our approach permits quantifying per-observation contributions to the classification outcome. We extensively compare our method with existing algorithms on multiple healthcare time series datasets and demonstrate that it performs competitively whilst significantly reducing runtime.", "keywords": null, "venue": "Proceedings of the 37 th International Conference on Machine Learning, Online, PMLR 119", "authors": ["Horn, Max", "Moor, Michael", "Bock, Christian", "Rieck, Bastian", "Borgwardt, Karsten"], "url": null, "doi": null}}
{"document_id": "LuoYe2020", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2020, "arxiv_id": null, "title": "HiTANet: Hierarchical Time-Aware Attention Networks for Risk Prediction on Electronic Health Records", "abstract": "Deep learning methods especially recurrent neural network based models have demonstrated early success in disease risk prediction on longitudinal patient data. Existing works follow a strong assumption to implicitly assume the stationary disease progression during each time period, and thus, take a homogeneous way to decay the information from previous time steps for all patients. However, in reality, disease progression is non-stationary. Besides, the key time steps for a target disease vary among patients. To leverage time information for risk prediction in a more reasonable way, we propose a new hierarchical time-aware attention network, named HiTANet, which imitates the decision making process of doctors in risk prediction. Particularly, HiTANet models time information in local and global stages. The local evaluation stage has a time-aware Transformer that embeds time information into visit-level embedding and generates local attention weight for each visit. The global synthesis stage further adopts a time-aware key-query attention mechanism to assign global weights to different time steps. Finally, the two types of attention weights are dynamically combined to generate the patient representations for further risk prediction. We evaluate HiTANet on three real-world datasets. Compared with the best results among twelve competing baselines, HiTANet achieves over 7% in terms of F1 score on all datasets, which demonstrates the effectiveness of the proposed model and the necessity of modeling time information in risk prediction task.", "keywords": ["risk prediction", "healthcare informatics", "attention mechanism", "transformer"], "venue": "KDD '20", "authors": ["Luo, Junyu", "Ye, Muchao", "Xiao, Cao", "Fenglong"], "url": "https://doi.org/10.1145/3394486.3403107", "doi": "10.1145/3394486.3403107"}}
{"document_id": "CuiKe2020", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2020, "arxiv_id": null, "title": "Stacked bidirectional and unidirectional LSTM recurrent neural network for forecasting network-wide traffic state with missing values", "abstract": "Short-term traffic forecasting based on deep learning methods, especially recurrent neural networks (RNN), has received much attention in recent years. However, the potential of RNN-based models in traffic forecasting has not yet been fully exploited in terms of the predictive power of spatial–temporal data and the capability of handling missing data. In this paper, we focus on RNN-based models and attempt to reformulate the way to incorporate RNN and its variants into traffic prediction models. A stacked bidirectional and unidirectional LSTM network architecture (SBU-LSTM) is proposed to assist the design of neural network structures for traffic state forecasting. As a key component of the architecture, the bidirectional LSTM (BDLSM) is exploited to capture the forward and backward temporal dependencies in spatiotemporal data. To deal with missing values in spatial–temporal data, we also propose a data imputation mechanism in the LSTM structure (LSTM-I) by designing an imputation unit to infer missing values and assist traffic prediction. The bidirectional version of LSTM-I is incorporated in the SBU-LSTM architecture. Two real-world network-wide traffic state datasets are used to conduct experiments and published to facilitate further traffic prediction research. The prediction performance of multiple types of multi-layer LSTM or BDLSTM models is evaluated. Experimental results indicate that the proposed SBU-LSTM architecture, especially the two-layer BDLSTM network, can achieve superior performance for the network-wide traffic prediction in both accuracy and robustness. Further, comprehensive comparison results show that the proposed data imputation mechanism in the RNN-based models can achieve outstanding prediction performance when the model’s input data contains different patterns of missing values.", "keywords": ["recurrent neural network", "bidirectional lstm", "backward dependency", "network-wide traffic prediction", "missing data", "data imputation"], "venue": "Transportation Research Part C", "authors": ["Cui, Zhiyong", "Ke, Ruimin", "Pu, Ziyuan", "Wang, Yinhai"], "url": "https://doi.org/10.1016/j.trc.2020.102674", "doi": "10.1016/j.trc.2020.102674"}}
{"document_id": "KidgerMorrill2020", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2020, "arxiv_id": null, "title": "Neural Controlled Differential Equations for Irregular Time Series", "abstract": "Neural ordinary differential equations are an attractive option for modelling\ntemporal dynamics.\nHowever, a fundamental issue is that the solution to an\nordinary differential equation is determined by its initial condition, and there\nis no mechanism for adjusting the trajectory based on subsequent observations.\nHere, we demonstrate how this may be resolved through the well-understood\nmathematics of controlled differential equations. The resulting neural controlled\ndifferential equation model is directly applicable to the general setting of partially-\nobserved irregularly-sampled multivariate time series, and (unlike previous work\non this problem) it may utilise memory-efﬁcient adjoint-based backpropagation\neven across observations. We demonstrate that our model achieves state-of-the-art\nperformance against similar (ODE or RNN based) models in empirical studies on\na range of datasets. Finally we provide theoretical results demonstrating universal\napproximation, and that our model subsumes alternative ODE models.", "keywords": null, "venue": "34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.", "authors": ["Kidger, Patrick", "Morrill, James", "Foster, James", "Lyons, Terry"], "url": null, "doi": null}}
{"document_id": "LechnerHasani2020", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2020, "arxiv_id": "2006.04418v4", "title": "Learning Long-Term Dependencies in Irregularly-Sampled Time Series", "abstract": "Recurrent neural networks (RNNs) with continuous-time hidden states are a natural\nﬁt for modeling irregularly-sampled time series. These models, however, face\ndifﬁculties when the input data possess long-term dependencies. We prove that\nsimilar to standard RNNs, the underlying reason for this issue is the vanishing or\nexploding of the gradient during training. This phenomenon is expressed by the\nordinary differential equation (ODE) representation of the hidden state, regardless\nof the ODE solver’s choice. We provide a solution by designing a new algorithm\nbased on the long short-term memory (LSTM) that separates its memory from its\ntime-continuous state. This way, we encode a continuous-time dynamical ﬂow\nwithin the RNN, allowing it to respond to inputs arriving at arbitrary time-lags\nwhile ensuring a constant error propagation through the memory path. We call\nthese RNN models ODE-LSTMs. We experimentally show that ODE-LSTMs\noutperform advanced RNN-based counterparts on non-uniformly sampled data\nwith long-term dependencies. All code and data is available at https://github.\ncom/mlech26l/ode-lstms.", "keywords": null, "venue": "arXiv", "authors": ["Lechner, Mathias", "Hasani, Ramin"], "url": "https://github.com/mlech26l/ode-lstms", "doi": null}}
{"document_id": "TanYe2020", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2020, "arxiv_id": null, "title": "DATA-GRU: Dual-Attention Time-Aware Gated Recurrent Unit for Irregular Multivariate Time Series", "abstract": "Due to the discrepancy of diseases and symptoms, patients usually visit hospitals irregularly and different physiological variables are examined at each visit, producing large amounts of irregular multivariate time series (IMTS) data with missing values and varying intervals. Existing methods process IMTS into regular data so that standard machine learning models can be employed. However, time intervals are usually determined by the status of patients, while missing values are caused by changes in symptoms. Therefore, we propose a novel end-to-end Dual-Attention Time-Aware Gated Recurrent Unit (DATA-GRU) for IMTS to predict the mortality risk of patients. In particular, DATA-GRU is able to: 1) preserve the informative varying intervals by introducing a time-aware structure to directly adjust the influence of the previous status in coordination with the elapsed time, and 2) tackle missing values by proposing a novel dual-attention structure to jointly consider data-quality and medical-knowledge. A novel unreliability-aware attention mechanism is designed to handle the diversity in the reliability of different data, while a new symptom-aware attention mechanism is proposed to extract medical reasons from original clinical records. Extensive experimental results on two real-world datasets demonstrate that DATA-GRU can significantly outperform state-of-the-art methods and provide meaningful clinical interpretation.", "keywords": null, "venue": "The Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI-20)", "authors": ["Tan, Qingxiong", "Ye, Mang", "Yang, Baoyao", "Liu, Si-Qi", "Andy Jinhua", "Yip, Terry Cheuk-Fung", "Wong, Grace Lai-Hung", "Yuen, Pong C."], "url": null, "doi": null}}
{"document_id": "ShuklaMarlin2021", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2021, "arxiv_id": "2101.10318v2", "title": "MULTI-TIME ATTENTION NETWORKS FOR IRREGULARLY SAMPLED TIME SERIES", "abstract": "Irregular sampling occurs in many time series modeling applications where it presents a signiﬁcant challenge to standard deep learning models. This work is motivated by the analysis of physiological time series data in electronic health records, which are sparse, irregularly sampled, and multivariate. In this paper, we propose a new deep learning framework for this setting that we call Multi-Time Attention Networks. Multi-Time Attention Networks learn an embedding of continuous time values and use an attention mechanism to produce a ﬁxed-length representation of a time series containing a variable number of observations. We investigate the performance of this framework on interpolation and classiﬁcation tasks using multiple datasets. Our results show that the proposed approach performs as well or better than a range of baseline and recently proposed models while offering signiﬁcantly faster training times than current state-of-the-art methods.", "keywords": null, "venue": "ICLR", "authors": ["Shukla, Satya Narayan", "Marlin, Benjamin M."], "url": "https://arxiv.org/abs/2101.10318v2", "doi": null}}
{"document_id": "MorrillSalvi2021", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2021, "arxiv_id": null, "title": "Neural Rough Differential Equations for Long Time Series", "abstract": "Neural controlled differential equations (CDEs) are the continuous-time analogue of recurrent neural networks, as Neural ODEs are to residual networks, and offer a memory-efficient continuous-time way to model functions of potentially irregular time series. Existing methods for computing the forward pass of a Neural CDE involve embedding the incoming time series into path space, often via interpolation, and using evaluations of this path to drive the hidden state. Here, we use rough path theory to extend this formulation. Instead of directly embedding into path space, we instead represent the input signal over small time intervals through its log-signature, which are statistics describing how the signal drives a CDE. This is the approach for solving rough differential equations (RDEs), and correspondingly we describe our main contribution as the introduction of Neural RDEs. This extension has a purpose: by generalising the Neural CDE approach to a broader class of driving signals, we demonstrate particular advantages for tackling long time series. In this regime, we demonstrate efficacy on problems of length up to 17k observations and observe significant training speed-ups, improvements in model performance, and reduced memory requirements compared to existing approaches.", "keywords": null, "venue": "Proceedings of the 38th International Conference on Machine Learning (PMLR 139)", "authors": ["Morrill, James", "Salvi, Cristopher", "Kidger, Patrick", "Foster, James"], "url": null, "doi": null}}
{"document_id": "HasaniLechner2021", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2021, "arxiv_id": null, "title": "Liquid Time-Constant Networks", "abstract": "We introduce a new class of time-continuous recurrent neural\nnetwork models. Instead of declaring a learning system’s dy-\nnamics by implicit nonlinearities, we construct networks of\nlinear ﬁrst-order dynamical systems modulated via nonlinear\ninterlinked gates. The resulting models represent dynamical\nsystems with varying (i.e., liquid) time-constants coupled to\ntheir hidden state, with outputs being computed by numeri-\ncal differential equation solvers. These neural networks ex-\nbibit stable and bounded behavior, yield superior expressivity\nwithin the family of neural ordinary differential equations,\nand give rise to improved performance on time-series predic-\ntion tasks. To demonstrate these properties, we ﬁrst take a\ntheoretical approach to ﬁnd bounds over their dynamics, and\ncompute their expressive power by the trajectory length mea-\nsure in a latent trajectory space. We then conduct a series of\ntime-series prediction experiments to manifest the approxi-\nmation capability of Liquid Time-Constant Networks (LTCs)\ncompared to classical and modern RNNs.", "keywords": null, "venue": "The Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI-21)", "authors": ["Hasani, Ramin", "Lechner, Mathias", "Amini, Alexander", "Rus, Daniela", "Grosu, Radu"], "url": null, "doi": null}}
{"document_id": "XiaSuliafu2021", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2021, "arxiv_id": null, "title": "Heavy Ball Neural Ordinary Differential Equations", "abstract": "We propose heavy ball neural ordinary differential equations (HBNODEs), leveraging the continuous limit of the classical momentum accelerated gradient descent, to improve neural ODEs (NODEs) training and inference. HBNODEs have two properties that imply practical advantages over NODEs: (i) The adjoint state of an HBNODE also satisfies an HBNODE, accelerating both forward and backward ODE solvers, thus significantly reducing the number of function evaluations (NFEs) and improving the utility of the trained models. (ii) The spectrum of HBNODEs is well structured, enabling effective learning of long-term dependencies from complex sequential data. We verify the advantages of HBNODEs over NODEs on benchmark tasks, including image classification, learning complex dynamics, and sequential modeling. Our method requires remarkably fewer forward and backward NFEs, is more accurate, and learns long-term dependencies more effectively than the other ODE-based neural network models. Code is available at https://github.com/hedixia/HeavyBallNODE.", "keywords": null, "venue": "35th Conference on Neural Information Processing Systems (NeurIPS 2021)", "authors": ["Xia, Hedi", "Suliafu, Vai", "Ji, Hangjie", "Nguyen, Tan M.", "Bertozzi, Andrea L.", "Osher, Stanley J.", "Wang, Bao"], "url": "https://github.com/hedixia/HeavyBallNODE", "doi": null}}
{"document_id": "ChienChen2021", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2021, "arxiv_id": null, "title": "CONTINUOUS-TIME SELF-ATTENTION IN NEURAL DIFFERENTIAL EQUATION", "abstract": "Neural differential equation (NDE) is recently developed as a continuous-time state machine which can faithfully represent irregularly-sampled sequence data. NDE is seen as a substantial extension of recurrent neural network (RNN) which conducts discrete-time state representation for regularly-sampled data. This study presents a new continuous-time attention to improve sequential learning where the region of interest in continuous-time state trajectory over observed as well as missing samples is sufficiently attended. However, the attention score, calculated by relating between a query and a sequence, is memory demanding because self-attention should treat all time observations as query vectors to feed them into ordinary differential equation (ODE) solver. To deal with this issue, we develop a new form of dynamics for continuous-time attention where the causality property is adopted such that query vector is fed into ODE solver up to current time. The experiments on irregularly-sampled human activities and medical features show that this method obtains desirable performance with efficient memory consumption.", "keywords": ["sequential learning", "neural differential equation", "attention mechanism", "causal attention"], "venue": "2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)", "authors": ["Chien, Jen-Tzung", "Chen, Yi-Hsiang"], "url": null, "doi": "10.1109/ICASSP39728.2021.9414104"}}
{"document_id": "XuRuan2021", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2021, "arxiv_id": "arXiv:2103.15213v1", "title": "A Temporal Kernel Approach for Deep Learning with Continuous-Time Information", "abstract": "Sequential deep learning models such as RNN, causal CNN and attention mechanism do not readily consume continuous-time information. Discretizing the temporal data, as we show, causes inconsistency even for simple continuous-time processes. Current approaches often handle time in a heuristic manner to be consistent with the existing deep learning architectures and implementations. In this paper, we provide a principled way to characterize continuous-time systems using deep learning tools. Notably, the proposed approach applies to all the major deep learning architectures and requires little modifications to the implementation. The critical insight is to represent the continuous-time system by composing neural networks with a temporal kernel, where we gain our intuition from the recent advancements in understanding deep learning with Gaussian process and neural tangent kernel. To represent the temporal kernel, we introduce the random feature approach and convert the kernel learning problem to spectral density estimation under reparameterization. We further prove the convergence and consistency results even when the temporal kernel is non-stationary, and the spectral density is misspecified. The simulations and real-data experiments demonstrate the empirical effectiveness of our temporal kernel approach in a broad range of settings.", "keywords": null, "venue": "ICLR 2021", "authors": ["Xu, Da", "Ruan, Chuanwei", "Korpeoglu, Evren", "Kuamr, Sushant", "Achan, Kannan"], "url": null, "doi": null}}
{"document_id": "ZhangZheng2023", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2023, "arxiv_id": null, "title": "Warpformer: A Multi-scale Modeling Approach for Irregular Clinical Time Series", "abstract": "Irregularly sampled multivariate time series are ubiquitous in various fields, particularly in healthcare, and exhibit two key characteristics: intra-series irregularity and inter-series discrepancy. Intra-series irregularity refers to the fact that time-series signals are often recorded at irregular intervals, while inter-series discrepancy refers to the significant variability in sampling rates among diverse series. However, recent advances in irregular time series have primarily focused on addressing intra-series irregularity, overlooking the issue of inter-series discrepancy. To bridge this gap, we present Warpformer, a novel approach that fully considers these two characteristics. In a nutshell, Warpformer has several crucial designs, including a specific input representation that explicitly characterizes both intra-series irregularity and inter-series discrepancy, a warping module that adaptively unifies irregular time series in a given scale, and a customized attention module for representation learning. Additionally, we stack multiple warping and attention modules to learn at different scales, producing multi-scale representations that balance coarse-grained and fine-grained signals for downstream tasks. We conduct extensive experiments on widely used datasets and a new large-scale benchmark built from clinical databases. The results demonstrate the superiority of Warpformer over existing state-of-the-art approaches.", "keywords": ["clinical time series", "irregularly sampled time series", "multi-scale representation"], "venue": "Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD '23)", "authors": ["Zhang, Jiawen", "Zheng, Shun", "Cao, Wei", "Bian, Jiang", "Li, Jia"], "url": "https://doi.org/10.1145/3580305.3599543", "doi": "10.1145/3580305.3599543"}}
{"document_id": "WeiPeng2023", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2023, "arxiv_id": null, "title": "Compatible Transformer for Irregularly Sampled Multivariate Time Series", "abstract": "To analyze multivariate time series, most previous methods assume regular subsampling of time series, where the interval between adjacent measurements and the number of samples remain unchanged. Practically, data collection systems could produce irregularly sampled time series due to sensor failures and interventions. However, existing methods designed for regularly sampled multivariate time series cannot directly handle irregularity owing to misalignment along both temporal and variate dimensions. To fill this gap, we propose Compatible Transformer (CoFormer), a transformer-based encoder to achieve comprehensive temporal-interaction feature learning for each individual sample in irregular multivariate time series. In CoFormer, we view each sample as a unique variate-time point and leverage intra-variate/inter-variate attentions to learn sample-wise temporal/interaction features based on intra-variate/inter-variate neighbors. With CoFormer as the core, we can analyze irregularly sampled multivariate time series for many downstream tasks, including classification and prediction. We conduct extensive experiments on 3 real-world datasets and validate that the proposed CoFormer significantly and consistently outperforms existing methods. Code will be avilable at https://github.com/MediaBrain-SJTU/CoFormer.", "keywords": ["multivariate time series", "irregularly sampling"], "venue": "2023 IEEE International Conference on Data Mining (ICDM)", "authors": ["Wei, Yuxi", "Peng, Juntong", "He, Tong", "Xu, Chenxin", "Zhang, Jian", "Pan, Shirui", "Chen, Siheng"], "url": "https://github.com/MediaBrain-SJTU/CoFormer", "doi": "10.1109/ICDM58522.2023.00183"}}
{"document_id": "JhinShin2023", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2024, "arxiv_id": null, "title": "Attentive neural controlled differential equations for time-series classification and forecasting", "abstract": "Neural networks inspired by differential equations have proliferated for the past several years, of which neural ordinary differential equations (NODEs) and neural controlled differential equations (NCDEs) are two representative examples. In theory, NCDEs exhibit better representation learning capability for time-series data than NODEs. In particular, it is known that NCDEs are suitable for processing irregular time-series data. Whereas NODEs have been successfully extended to adopt attention, methods to integrate attention into NCDEs have not yet been studied. To this end, we present attentive neural controlled differential equations (ANCDEs) for time-series classification and forecasting, where dual NCDEs are used: one for generating attention values and the other for evolving hidden vectors for a downstream machine learning task. We conduct experiments on 5 real-world time-series datasets and 11 baselines. After dropping some values, we also conduct experiments on irregular time-series. Our method consistently shows the best accuracy in all cases by non-trivial margins. Our visualizations also show that the presented attention mechanism works as intended by focusing on crucial information.", "keywords": ["time-series data", "neural controlled differential equations", "attention"], "venue": "Knowledge and Information Systems", "authors": ["Jhin, Sheo Yon", "Shin, Heejoo", "Kim, Sujie", "Hong, Seoyoung", "Jo, Minju", "Park, Solhee", "Park, Noseong", "Lee, Seungbeom", "Maeng, Hwiyoung", "Jeon, Seungmin"], "url": "https://doi.org/10.1007/s10115-023-01977-5", "doi": "10.1007/s10115-023-01977-5"}}
{"document_id": "HuangYang2024", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2024, "arxiv_id": null, "title": "DNA-T: Deformable Neighborhood Attention Transformer for Irregular Medical Time Series", "abstract": "The real-world Electronic Health Records (EHRs) present irregularities due to changes in the patient’s health status, resulting in various time intervals between observations and different physiological variables examined at each observation point. There have been recent applications of Transformer-based models in the field of irregular time series. However, the full attention mechanism in Transformer overly focuses on distant information, ignoring the short-term correlations of the condition. Thereby, the model is not able to capture localized changes or short-term fluctuations in patients’ conditions. Therefore, we propose a novel end-to-end Deformable Neighborhood Attention Transformer (DNA-T) for irregular medical time series. The DNA-T captures local features by dynamically adjusting the receptive field of attention and aggregating relevant deformable neighborhoods in irregular time series. Specifically, we design a Deformable Neighborhood Attention (DNA) module that enables the network to attend to relevant neighborhoods by drifting the receiving field of neighborhood attention. The DNA enhances the model’s sensitivity to local information and representation of local features, thereby capturing the correlation of localized changes in patients’ conditions. We conduct extensive experiments to validate the effectiveness of DNA-T, outperforming existing state-of-the-art methods in predicting the mortality risk of patients. Moreover, we visualize an example to validate the effectiveness of the proposed DNA.", "keywords": ["deformable neighborhood attention", "medical time series", "transformer"], "venue": "IEEE Journal of Biomedical and Health Informatics", "authors": ["Huang, Jianxuan", "Yang, Baoyao", "Yin, Kejing", "Xu, Jingwen"], "url": "https://github.com/Nekumiya-x/DNA-T", "doi": "10.1109/JBHI.2024.3395446"}}
{"document_id": "ChenRen2024", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2023, "arxiv_id": null, "title": "ContiFormer: Continuous-Time Transformer for Irregular Time Series Modeling", "abstract": "Modeling continuous-time dynamics on irregular time series is critical to account for data evolution and correlations that occur continuously. Traditional methods including recurrent neural networks or Transformer models leverage inductive bias via powerful neural architectures to capture complex patterns. However, due to their discrete characteristic, they have limitations in generalizing to continuous-time data paradigms. Though neural ordinary differential equations (Neural ODEs) and their variants have shown promising results in dealing with irregular time series, they often fail to capture the intricate correlations within these sequences. It is challenging yet demanding to concurrently model the relationship between input data points and capture the dynamic changes of the continuous-time system. To tackle this problem, we propose ContiFormer that extends the relation modeling of vanilla Transformer to the continuous-time domain, which explicitly incorporates the modeling abilities of continuous dynamics of Neural ODEs with the attention mechanism of Transformers. We mathematically characterize the expressive power of ContiFormer and illustrate that, by curated designs of function hypothesis, many Transformer variants specialized in irregular time series modeling can be covered as a special case of ContiFormer. A wide range of experiments on both synthetic and real-world datasets have illustrated the superior modeling capacities and prediction performance of ContiFormer on irregular time series data. The project link is https://seqml.github.io/contiformer/.", "keywords": null, "venue": "37th Conference on Neural Information Processing Systems (NeurIPS 2023)", "authors": ["Chen, Yuqi", "Ren, Kan", "Wang, Yansen", "Fang, Yuchen", "Sun, Weiwei", "Li, Dongsheng"], "url": "https://seqml.github.io/contiformer/", "doi": null}}
{"document_id": "ZhangYin2024", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2024, "arxiv_id": null, "title": "Irregular Multivariate Time Series Forecasting: A Transformable Patching Graph Neural Networks Approach", "abstract": "Forecasting of Irregular Multivariate Time Series (IMTS) is critical for numerous areas, such as healthcare, biomechanics, climate science, and astronomy. Despite existing research addressing irregularities in time series through ordinary differential equations, the challenge of modeling correlations between asynchronous IMTS remains underexplored. To bridge this gap, this study proposes Transformable Patching Graph Neural Networks (T-PATCHGNN), which transforms each univariate irregular time series into a series of transformable patches encompassing a varying number of observations with uniform temporal resolution. It seamlessly facilitates local semantics capture and inter-time series correlation modeling while avoiding sequence length explosion in aligned IMTS. Building on the aligned patching outcomes, we then present time-adaptive graph neural networks to model dynamic inter-time series correlation based on a series of learned time-varying adaptive graphs. We demonstrate the remarkable superiority of T-PATCHGNN on a comprehensive IMTS forecasting benchmark we build, which contains four real-world scientific datasets covering healthcare, biomechanics and climate science, and seventeen competitive baselines adapted from relevant research fields.", "keywords": null, "venue": "Proceedings of the 41st International Conference on Machine Learning (PMLR 235)", "authors": ["Zhang, Weijia", "Yin, Chenlong", "Liu, Hao", "Zhou, Xiaofang", "Xiong, Hui"], "url": "https://github.com/usail-hkust/t-PatchGNN", "doi": null}}
{"document_id": "Yalavarthi2024", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2024, "arxiv_id": null, "title": "GraFITi: Graphs for Forecasting Irregularly Sampled Time Series", "abstract": "Forecasting irregularly sampled time series with missing values is a crucial task for numerous real-world applications such as healthcare, astronomy, and climate sciences. State-of-the-art approaches to this problem rely on Ordinary Differential Equations (ODEs) which are known to be slow and often require additional features to handle missing values. To address this issue, we propose a novel model using Graphs for Forecasting Irregularly Sampled Time Series with missing values which we call GraFITi. GraFITi first converts the time series to a Sparsity Structure Graph which is a sparse bipartite graph, and then reformulates the forecasting problem as the edge weight prediction task in the graph. It uses the power of Graph Neural Networks to learn the graph and predict the target edge weights. GraFITi has been tested on 3 real-world and 1 synthetic irregularly sampled time series dataset with missing values and compared with various state-of-the-art models. The experimental results demonstrate that GraFITi improves the forecasting accuracy by up to 17% and reduces the run time up to 5 times compared to the state-of-the-art forecasting models.", "keywords": null, "venue": "The Thirty-Eighth AAAI Conference on Artificial Intelligence (AAAI-24)", "authors": ["Yalavarthi, Vijaya Krishna", "Madhusudhanan, Kiran", "Scholz, Randolf", "Ahmed, Nourhan", "Burchert, Johannes", "Jawed, Shayan", "Born, Stefan", "Schmidt-Thieme, Lars"], "url": null, "doi": null}}
{"document_id": "ChenZhou2025", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2025, "arxiv_id": null, "title": "Efficient Anomaly Detection of Irregular Sequences in Ct-Echo Model Space", "abstract": "Efficient anomaly detection of irregular sequences, especially those characterized by non-uniform sampling from discontinuous operations or unreliable sensors, presents challenges across various fields. In response, this paper introduces irregular-sequence classification in \"Ct-Echo Model Space\". A novel Continuous-time Echo Network (Ct-Echo) is proposed to fit irregular sequences, efficiently capturing their inherent dynamic characteristics. Ct-Echo utilizes the \"Echo\" mechanism, where history information influences the current state and diminishes over time, and employs Ordinary Differential Equation (ODE) to construct continuous-time transition of hidden states. Each sequence is individually fitted via Ct-Echo to derive a readout model. These fitted models, capturing the dynamic characteristics of the original data, serve as representations of the corresponding sequences, thus mapping the original data from the data space to the Ct-Echo model space. Anomaly detection is further performed in this model space, evaluating differences between models rather than directly on the original sequences. Our method enhances real-time processing and lessens reliance on the amount of labeled training data, as demonstrated by experimental studies.", "keywords": null, "venue": "The Thirty-Ninth AAAI Conference on Artificial Intelligence (AAAI-25)", "authors": ["Chen, Ao", "Zhou, Xiren", "Chen, Huanhuan"], "url": null, "doi": null}}
{"document_id": "LiMarlin2016", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2016, "arxiv_id": null, "title": "A scalable end-to-end Gaussian process adapter for irregularly sampled time series classiﬁcation", "abstract": "We present a general framework for classiﬁcation of sparse and irregularly-sampled time series. The properties of such time series can result in substantial uncertainty about the values of the underlying temporal processes, while making the data difﬁcult to deal with using standard classiﬁcation methods that assume ﬁxed-dimensional feature spaces. To address these challenges, we propose an uncertainty-aware classiﬁcation framework based on a special computational layer we refer to as the Gaussian process adapter that can connect irregularly sampled time series data to any black-box classiﬁer learnable using gradient descent. We show how to scale up the required computations based on combining the structured kernel interpolation framework and the Lanczos approximation method, and how to discriminatively train the Gaussian process adapter in combination with a number of classiﬁers end-to-end using backpropagation.", "keywords": null, "venue": "30th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain.", "authors": ["Li, Steven Cheng-Xian", "Marlin, Benjamin"], "url": null, "doi": null}}
{"document_id": "ChePurushothamLi2018", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2018, "arxiv_id": null, "title": "Hierarchical Deep Generative Models for Multi-Rate Multivariate Time Series", "abstract": "Multi-Rate Multivariate Time Series (MR-MTS) are the multivariate time series observations which come with various sampling rates and encode multiple temporal dependencies. State-space models such as Kalman filters and deep learning models such as deep Markov models are mainly designed for time series data with the same sampling rate and cannot capture all the dependencies present in the MR-MTS data. To address this challenge, we propose the Multi-Rate Hierarchical Deep Markov Model (MR-HDMM), a novel deep generative model which uses the latent hierarchical structure with a learnable switch mechanism to capture the temporal dependencies of MR-MTS. Experimental results on two real-world datasets demonstrate that our MR-HDMM model outperforms the existing state-of-the-art deep learning and state-space models on forecasting and interpolation tasks. In addition, the latent hierarchies in our model provide a way to show and interpret the multiple temporal dependencies.", "keywords": null, "venue": "Proceedings of the 35th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80", "authors": ["Che, Zhengping", "Purushotham, Sanjay", "Li, Guangyu", "Jiang, Bo", "Liu, Yan"], "url": null, "doi": null}}
{"document_id": "ChenRubanova2018", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2018, "arxiv_id": null, "title": "Neural Ordinary Differential Equations", "abstract": "We introduce a new family of deep neural network models. Instead of specifying a discrete sequence of hidden layers, we parameterize the derivative of the hidden state using a neural network. The output of the network is computed using a black-box differential equation solver. These continuous-depth models have constant memory cost, adapt their evaluation strategy to each input, and can explicitly trade numerical precision for speed. We demonstrate these properties in continuous-depth residual networks and continuous-time latent variable models. We also construct continuous normalizing flows, a generative model that can train by maximum likelihood, without partitioning or ordering the data dimensions. For training, we show how to scalably backpropagate through any ODE solver, without access to its internal operations. This allows end-to-end training of ODEs within larger models.", "keywords": null, "venue": "32nd Conference on Neural Information Processing Systems (NeurIPS 2018)", "authors": ["Chen, Ricky T. Q.", "Rubanova, Yulia", "Bettencourt, Jesse", "Duvenaud, David"], "url": null, "doi": null}}
{"document_id": "LiWong2020", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2020, "arxiv_id": null, "title": "Scalable Gradients for Stochastic Differential Equations", "abstract": "The adjoint sensitivity method scalably computes gradients of solutions to ordinary differential equations. We generalize this method to stochastic differential equations, allowing time-efficient and constant-memory computation of gradients with high-order adaptive solvers. Specifically, we derive a stochastic differential equation whose solution is the gradient, a memory-efficient algorithm for caching noise, and conditions under which numerical solutions converge. In addition, we combine our method with gradient-based stochastic variational inference for latent stochastic differential equations. We use our method to fit stochastic dynamics defined by neural networks, achieving competitive performance on a 50-dimensional motion capture dataset.", "keywords": null, "venue": "Proceedings of the 23rd International Conference on Artificial Intelligence and Statistics (AISTATS)", "authors": ["Li, Xuechen", "Wong, Ting-Kam Leonard", "Chen, Ricky T. Q.", "Duvenaud, David"], "url": null, "doi": null}}
{"document_id": "WuNi2021", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2021, "arxiv_id": null, "title": "Dynamic Gaussian Mixture based Deep Generative Model For Robust Forecasting on Sparse Multivariate Time Series", "abstract": "Forecasting on sparse multivariate time series (MTS) aims to model the predictors of future values of time series given their incomplete past, which is important for many emerging applications. However, most existing methods process MTS’s individually, and do not leverage the dynamic distributions underlying the MTS’s, leading to sub-optimal results when the sparsity is high. To address this challenge, we propose a novel generative model, which tracks the transition of latent clusters, instead of isolated feature representations, to achieve robust modeling. It is characterized by a newly designed dynamic Gaussian mixture distribution, which captures the dynamics of clustering structures, and is used for emitting time series. The generative model is parameterized by neural networks. A structured inference network is also designed for enabling inductive analysis. A gating mechanism is further introduced to dynamically tune the Gaussian mixture distributions. Extensive experimental results on a variety of real-life datasets demonstrate the effectiveness of our method.", "keywords": null, "venue": "The Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI-21)", "authors": ["Wu, Yinjun", "Ni, Jingchao", "Cheng, Wei", "Zong, Bo", "Song, Dongjin", "Chen, Zhengzhang", "Liu, Yanchi", "Zhang, Xuchao", "Chen, Haifeng", "Davidson, Susan B."], "url": null, "doi": null}}
{"document_id": "HessMelnychuk2024", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2024, "arxiv_id": null, "title": "BAYESIAN NEURAL CONTROLLED DIFFERENTIAL EQUATIONS FOR TREATMENT EFFECT ESTIMATION", "abstract": "Treatment effect estimation in continuous time is crucial for personalized medicine. However, existing methods for this task are limited to point estimates of the potential outcomes, whereas uncertainty estimates have been ignored. Needless to say, uncertainty quantification is crucial for reliable decision-making in medical applications. To fill this gap, we propose a novel Bayesian neural controlled differential equation (BNCDE) for treatment effect estimation in continuous time. In our BNCDE, the time dimension is modeled through a coupled system of neural controlled differential equations and neural stochastic differential equations, where the neural stochastic differential equations allow for tractable variational Bayesian inference. Thereby, for an assigned sequence of treatments, our BNCDE provides meaningful posterior predictive distributions of the potential outcomes. To the best of our knowledge, ours is the first tailored neural method to provide uncertainty estimates of treatment effects in continuous time. As such, our method is of direct practical value for promoting reliable decision-making in medicine.", "keywords": null, "venue": "ICLR 2024", "authors": ["Hess, Konstantin", "Melnychuk, Valentyn", "Frauen, Dennis", "Feuerriegel, Stefan"], "url": null, "doi": null}}
{"document_id": "NaimanErichson2024", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2024, "arxiv_id": null, "title": "Generative Modeling of Regular and Irregular Time Series Data via Koopman VAEs", "abstract": "Generating realistic time series data is important for many engineering and scientific applications. Existing work tackles this problem using generative adversarial networks (GANs). However, GANs are unstable during training, and they can suffer from mode collapse. While variational autoencoders (VAEs) are known to be more robust to the these issues, they are (surprisingly) less considered for time series generation. In this work, we introduce Koopman VAE (KoVAE), a new generative framework that is based on a novel design for the model prior, and that can be optimized for either regular and irregular training data. Inspired by Koopman theory, we represent the latent conditional prior dynamics using a linear map. Our approach enhances generative modeling with two desired features: (i) incorporating domain knowledge can be achieved by leveraging spectral tools that prescribe constraints on the eigenvalues of the linear map; and (ii) studying the qualitative behavior and stability of the system can be performed using tools from dynamical systems theory. Our results show that KoVAE outperforms state-of-the-art GAN and VAE methods across several challenging synthetic and real-world time series generation benchmarks. Whether trained on regular or irregular data, KoVAE generates time series that improve both discriminative and predictive metrics. We also present visual evidence suggesting that KoVAE learns probability density functions that better approximate the empirical ground truth distribution.", "keywords": null, "venue": "ICLR 2024", "authors": ["Naiman, Ilan", "Erichson, N. Benjamin", "Ren, Pu", "Mahoney, Michael W.", "Azencot, Omri"], "url": null, "doi": null}}
{"document_id": "DupontDoucet2019", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2019, "arxiv_id": null, "title": "Augmented Neural ODEs", "abstract": "We show that Neural Ordinary Differential Equations (ODEs) learn representations that preserve the topology of the input space and prove that this implies the existence of functions Neural ODEs cannot represent. To address these limitations, we introduce Augmented Neural ODEs which, in addition to being more expressive models, are empirically more stable, generalize better and have a lower computational cost than Neural ODEs.", "keywords": null, "venue": "33rd Conference on Neural Information Processing Systems (NeurIPS)", "authors": ["Dupont, Emilien", "Doucet, Arnaud", "Teh, Yee Whye"], "url": null, "doi": null}}
{"document_id": "YildizHeinonen2019", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2019, "arxiv_id": null, "title": "ODE2VAE: Deep generative second order ODEs with Bayesian neural networks", "abstract": "We present Ordinary Differential Equation Variational Auto-Encoder (ODE2VAE),\na latent second order ODE model for high-dimensional sequential data. Lever-\naging the advances in deep generative models, ODE2VAE can simultaneously\nlearn the embedding of high dimensional trajectories and infer arbitrarily complex\ncontinuous-time latent dynamics. Our model explicitly decomposes the latent\nspace into momentum and position components and solves a second order ODE\nsystem, which is in contrast to recurrent neural network (RNN) based time series\nmodels and recently proposed black-box ODE techniques. In order to account for\nuncertainty, we propose probabilistic latent ODE dynamics parameterized by deep\nBayesian neural networks. We demonstrate our approach on motion capture, image\nrotation and bouncing balls datasets. We achieve state-of-the-art performance in\nlong term motion prediction and imputation tasks.", "keywords": null, "venue": "33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada.", "authors": ["Yıldız, Çağatay", "Heinonen, Markus", "Lähdesmäki, Harri"], "url": "https://github.com/cagatayyildiz/ODE2VAE", "doi": null}}
{"document_id": "FortuinBaranchuck2020", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2020, "arxiv_id": null, "title": "GP-VAE: Deep Probabilistic Multivariate Time Series Imputation", "abstract": "Multivariate time series with missing values are common in areas such as healthcare and finance, and have grown in number and complexity over the years. This raises the question whether deep learning methodologies can outperform classical data imputation methods in this domain. However, naïve applications of deep learning fall short in giving reliable confidence estimates and lack interpretability. We propose a new deep sequential latent variable model for dimensionality reduction and data imputation. Our modeling assumption is simple and interpretable: the high dimensional time series has a lower-dimensional representation which evolves smoothly in time according to a Gaussian process. The non-linear dimensionality reduction in the presence of missing data is achieved using a VAE approach with a novel structured variational approximation. We demonstrate that our approach outperforms several classical and deep learning-based data imputation methods on high-dimensional data from the domains of computer vision and healthcare, while additionally improving the smoothness of the imputations and providing interpretable uncertainty estimates.", "keywords": null, "venue": "Proceedings of the 23rd International Conference on Artificial Intelligence and Statistics (AISTATS)", "authors": ["Fortuin, Vincent", "Baranchuk, Dmitry", "Rätsch, Gunnar", "Mandt, Stephan"], "url": null, "doi": null}}
{"document_id": "NordcliffeBodnar2020", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2020, "arxiv_id": null, "title": "On Second Order Behaviour in Augmented Neural ODEs", "abstract": "Neural Ordinary Differential Equations (NODEs) are a new class of models that transform data continuously through inﬁnite-depth architectures. The continuous nature of NODEs has made them particularly suitable for learning the dynamics of complex physical systems. While previous work has mostly been focused on ﬁrst order ODEs, the dynamics of many systems, especially in classical physics, are governed by second order laws. In this work, we consider Second Order Neural ODEs (SONODEs). We show how the adjoint sensitivity method can be extended to SONODEs and prove that the optimisation of a ﬁrst order coupled ODE is equivalent and computationally more efﬁcient. Furthermore, we extend the theoretical understanding of the broader class of Augmented NODEs (ANODEs) by showing they can also learn higher order dynamics with a minimal number of augmented dimensions, but at the cost of interpretability. This indicates that the advantages of ANODEs go beyond the extra space offered by the augmented dimensions, as originally thought. Finally, we compare SONODEs and ANODEs on synthetic and real dynamical systems and demonstrate that the inductive biases of the former generally result in faster training and better performance.", "keywords": null, "venue": "34th Conference on Neural Information Processing Systems (NeurIPS 2020)", "authors": ["Norcliffe, Alexander", "Bodnar, Cristian", "Day, Ben", "Simidjievski, Nikola", "Liò, Pietro"], "url": null, "doi": null}}
{"document_id": "CoelhoFernanda2024", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2024, "arxiv_id": null, "title": "Enhancing continuous time series modelling with a latent ODE-LSTM approach", "abstract": "Due to their dynamic properties such as irregular sampling rate and high-frequency sampling, Continuous Time Series (CTS) are found in many applications. Since CTS with irregular sampling rate are difficult to model with standard Recurrent Neural Networks (RNNs), RNNs have been generalised to have continuous-time hidden dynamics defined by a Neural Ordinary Differential Equation (Neural ODE), leading to the ODE-RNN model. Another approach that provides a better modelling is that of the Latent ODE model, which constructs a continuous-time model where a latent state is defined at all times. The Latent ODE model uses a standard RNN as the encoder and a Neural ODE as the decoder. However, since the RNN encoder leads to difficulties with missing data and ill-defined latent variables, a Latent ODE-RNN model has recently been proposed that uses a ODE-RNN model as the encoder instead. Both the Latent ODE and Latent ODE-RNN models are difficult to train due to the vanishing and exploding gradients problem. To overcome this problem, the main contribution of this paper is to propose and illustrate a new model based on a new Latent ODE using an ODE-LSTM (Long Short-Term Memory) network as an encoder - the Latent ODE-LSTM model. To limit the growth of the gradients, the Norm Gradient Clipping strategy was embedded on the Latent ODE-LSTM model. The performance evaluation of the new Latent ODE-LSTM (with and without Norm Gradient Clipping) for modelling CTS with regular and irregular sampling rates is then demonstrated. Numerical experiments show that the new Latent ODE-LSTM performs better than Latent ODE-RNNs and can avoid the vanishing and exploding gradients during training. Code implementations developed in this work are available at github.com/CeciliaCoelho/LatentODELSTM.", "keywords": ["machine learning", "neural ode", "latent ode", "rnn", "lstm", "latent ode-lstm", "gradient clipping"], "venue": "Applied Mathematics and Computation", "authors": ["Coelho, C.", "Costa, M. Fernanda P.", "Ferrás, L. L."], "url": "https://doi.org/10.1016/j.amc.2024.128727", "doi": "10.1016/j.amc.2024.128727"}}
{"document_id": "Yoon2019", "timestamp": "2025-11-09T23:39:43.348106+00:00", "source": "llm:gpt-5-mini", "prompt_version": null, "metadata": {"year": 2019, "arxiv_id": null, "title": "Time-series Generative Adversarial Networks", "abstract": "A good generative model for time-series data should preserve temporal dynamics, in the sense that new sequences respect the original relationships between variables across time. Existing methods that bring generative adversarial networks (GANs) into the sequential setting do not adequately attend to the temporal correlations unique to time-series data. At the same time, supervised models for sequence prediction—which allow ﬁner control over network dynamics—are inherently deterministic. We propose a novel framework for generating realistic time-series data that combines the ﬂexibility of the unsupervised paradigm with the control afforded by supervised training. Through a learned embedding space jointly optimized with both supervised and adversarial objectives, we encourage the network to adhere to the dynamics of the training data during sampling. Empirically, we evaluate the ability of our method to generate realistic samples using a variety of real and synthetic time-series datasets. Qualitatively and quantitatively, we ﬁnd that the proposed framework consistently and signiﬁcantly outperforms state-of-the-art benchmarks with respect to measures of similarity and predictive ability.", "keywords": null, "venue": "33rd Conference on Neural Information Processing Systems (NeurIPS)", "authors": ["Yoon, Jinsung", "Jarrett, Daniel", "Van Der Schaar, Mihaela"], "url": null, "doi": null}}
